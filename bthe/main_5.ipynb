{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Modelling - Recurrent neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import plotly.express as px\n",
    "from datetime import datetime\n",
    "import csv\n",
    "\n",
    "#ml\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "#data folder\n",
    "data_folder : str = \"data\"\n",
    "\n",
    "#plot styles\n",
    "plt_style_c = px.colors.sequential.haline #complex\n",
    "plt_style_s = px.colors.diverging.Portland #simple\n",
    "\n",
    "#decide if the data gets saved or not\n",
    "run_optim : bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example: https://towardsdatascience.com/time-series-prediction-with-lstm-in-tensorflow-42104db39340"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation function: \"selu\". Does not suffer from:\n",
    "- dying relu\n",
    "- vanshing gradient\n",
    "- source: https://towardsdatascience.com/gentle-introduction-to-selus-b19943068cd9\n",
    "- code: model.add(layers.Dense(64, activation='selu'))\n",
    "\n",
    "Kernel initializer: \"HeNormal\"\n",
    "- procudes deterministic results with the same random seed\n",
    "- source: https://keras.io/api/layers/initializers/\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Basics and base class for inheritance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(527, 27)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main = pd.read_csv(os.path.join(\"data\", \"df.csv\"), index_col = \"index\")\n",
    "df_main.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test years:\t[1988, 1999, 2010, 2021]\n",
      "test set:\t48\n",
      "train set:\t479\n"
     ]
    }
   ],
   "source": [
    "#create test set\n",
    "n_years_test = 4\n",
    "years = list(set(df_main[\"year\"].to_list()))\n",
    "years.sort()\n",
    "\n",
    "#set relevant years\n",
    "indexes = [int(len(years) * (i/n_years_test)) - 1 for i in range(1, 1 + n_years_test)]\n",
    "test_years = [years[i-1] for i in indexes] ##added minus 2 to get a better distributed data set\n",
    "\n",
    "#create df_test und df\n",
    "df = df_main[~df_main[\"year\"].isin(test_years)]\n",
    "df_test = df_main[df_main[\"year\"].isin(test_years)]\n",
    "\n",
    "print(f\"test years:\\t{test_years}\")\n",
    "print(f\"test set:\\t{df_test.shape[0]}\\ntrain set:\\t{df.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see: https://scikit-learn.org/stable/auto_examples/neural_networks/plot_mlp_alpha.html#sphx-glr-auto-examples-neural-networks-plot-mlp-alpha-py\n",
    "#see: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "#see: https://becominghuman.ai/what-does-feature-scaling-mean-when-to-normalize-data-and-when-to-standardize-data-c3de654405ed\n",
    "#see: https://www.tensorflow.org/tutorials/structured_data/time_series\n",
    "#see: https://towardsdatascience.com/preventing-data-leakage-in-your-machine-learning-model-9ae54b3cd1fb\n",
    "\n",
    "class Keras_base():\n",
    "\n",
    "    def __init__ (self, y_col : str, df : object, df_test : object ,run_optim : bool, data_folder : str, model_splitter : int):\n",
    "\n",
    "        #set base infromation\n",
    "        self.y_col : str            = y_col\n",
    "        self.df : object            = df\n",
    "        self.df_test                = df_test\n",
    "        self.run_optim : bool       = run_optim\n",
    "        self.model_splitter         = model_splitter #1 = v1, 2 = v2\n",
    "        self.valid_frac             = 0.2\n",
    "\n",
    "        #fixed model random seed\n",
    "        self.random_state            = 42\n",
    "        tf.random.set_seed(self.random_state)\n",
    "\n",
    "        #nn parameters\n",
    "        self.acitvation_func        = \"selu\"\n",
    "        self.solver                 = tf.keras.optimizers.legacy.SGD(learning_rate=0.1) #tf.keras.optimizers.SGD(learning_rate=0.0001) #tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        self.initializer            = tf.keras.initializers.HeNormal(seed = self.random_state)\n",
    "        self.loss_func              = tf.keras.losses.BinaryCrossentropy()\n",
    "        self.n_epochs               = 10\n",
    "\n",
    "        #arch params\n",
    "        self.lin_arch_scaling       = 2\n",
    "        self.cone_arch_scaling      = 2\n",
    "        self.cone_arch_base_power   = 4\n",
    "        self.n_layers               = 5\n",
    "\n",
    "        #set saving infos\n",
    "        self.log_file : str         = os.path.join(data_folder, \"optim_log.txt\")\n",
    "        self.result_file : str      = os.path.join(data_folder, \"rnnc_results.csv\")\n",
    "\n",
    "        #construct keras initializer with given random seed\n",
    "        self.initializer = tf.keras.initializers.HeNormal(seed = self.random_state)\n",
    "\n",
    "        #prepara data\n",
    "        self.__standardize()\n",
    "        self.__df_split()\n",
    "\n",
    "        if self.df_test is not None:\n",
    "            self.__prep_test_df()\n",
    "\n",
    "        self.__generate_archs()\n",
    "        self.n_features = self.X.shape[1]\n",
    "\n",
    "        #execute code bases on inputs\n",
    "        if self.run_optim:\n",
    "            self.run_optim_child()\n",
    "\n",
    "        #retrieve results from automation if it exists\n",
    "        self.__get_results()\n",
    "\n",
    "        return\n",
    "\n",
    "    def __generate_archs(self):\n",
    "\n",
    "        self.architectures : list = []\n",
    "        n_features = len(self.X.columns.tolist())\n",
    "\n",
    "        nodes_pow_2 = [2 ** (self.cone_arch_base_power + p) for p in range(1, self.n_layers + 1)][::-1]\n",
    "\n",
    "        for n_layer in range(1, self.n_layers + 1):\n",
    "\n",
    "            #linear\n",
    "            for size in [n_features / self.lin_arch_scaling ,n_features, n_features * self.lin_arch_scaling]:\n",
    "                arch_lin = [int(size)] * n_layer\n",
    "                self.architectures.append(arch_lin)\n",
    "\n",
    "            #cone\n",
    "            arch_cone = nodes_pow_2[:n_layer]\n",
    "            self.architectures.append(arch_cone)\n",
    "\n",
    "        return\n",
    "\n",
    "    def __standardize(self):\n",
    "\n",
    "        #unstandardized copy\n",
    "        self.df_unstand = self.df.copy()\n",
    "\n",
    "        #standardize columns\n",
    "        x_cols = self.df.columns.to_list(); x_cols.remove(self.y_col)\n",
    "        self.df[x_cols] = (self.df[x_cols] - self.df[x_cols].mean()) / self.df[x_cols].std()\n",
    "\n",
    "        #clean up all columns with no variation\n",
    "        #unneded_cols = self.df.describe().T[\"std\"].loc[self.df.describe().T[\"std\"] == 0].index.to_list()\n",
    "        #self.df.drop(labels = unneded_cols, axis = 1, inplace = True)\n",
    "\n",
    "        true_indexes = []\n",
    "\n",
    "        for index, value in self.df.std().isna().items():\n",
    "                if value == True:\n",
    "                    true_indexes.append(index)\n",
    "\n",
    "        self.df.drop(labels = true_indexes, axis = 1, inplace = True)\n",
    "\n",
    "        return\n",
    "\n",
    "    def __df_split(self):\n",
    "\n",
    "        #create X and y dfs\n",
    "        self.X = self.df.drop(labels = self.y_col, axis = 1)\n",
    "        self.y = self.df[self.y_col]\n",
    "\n",
    "        #create train and valid models\n",
    "        if self.model_splitter == 1:\n",
    "            self.__single_model_split_v1()\n",
    "        elif self.model_splitter == 2:\n",
    "            self.__single_model_split_v2()\n",
    "\n",
    "        return\n",
    "\n",
    "    def save_result(self, model_type, train_score, valid_score, arch): #add features\n",
    "\n",
    "        if os.path.isfile(self.result_file) is False:\n",
    "\n",
    "            file = open(self.result_file, \"w\", newline='')\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"model_type\",\"train_score\", \"valid_score\",\"arch\", \"valid_model_splitter\"]) #add features\n",
    "            file.close()\n",
    "\n",
    "        file = open(self.result_file, \"a\", newline='')\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([model_type, train_score, valid_score, arch, self.model_splitter]) #add features\n",
    "        file.close()\n",
    "\n",
    "        return\n",
    "\n",
    "    def __log(self, message):\n",
    "\n",
    "        #create log entry\n",
    "        log_time : str = datetime.now()\n",
    "        message = f\"source_mlp,{log_time},{message}\\n\"\n",
    "\n",
    "        #write log entry\n",
    "        file_object = open(self.log_file, 'a')\n",
    "        file_object.write(message)\n",
    "        file_object.close()\n",
    "\n",
    "        return\n",
    "\n",
    "    def __get_results(self):\n",
    "\n",
    "        self.results = pd.read_csv(self.result_file)\n",
    "\n",
    "    def __single_model_split_v1(self):\n",
    "\n",
    "        #split\n",
    "        index = round(self.df.shape[0] * self.valid_frac)\n",
    "\n",
    "        self.X_train = self.X.iloc[index:]\n",
    "        self.y_train = self.y.iloc[index:]\n",
    "\n",
    "        self.X_valid = self.X.iloc[:index]\n",
    "        self.y_valid = self.y.iloc[:index]\n",
    "\n",
    "        return\n",
    "\n",
    "    def __single_model_split_v2(self):\n",
    "\n",
    "        years = list(set(self.df[\"year\"].to_list()))\n",
    "        years.sort()\n",
    "\n",
    "        n_years = int(len(years) * self.valid_frac)\n",
    "        n_years_half = ((n_years % 2) + n_years) / 2 #round to even numbers and split in half\n",
    "\n",
    "        #get target year list\n",
    "        valid_years = years[round(((len(years) - 1) / 2) - n_years_half) : round((len(years) / 2 ) -1 )] + years[int(-n_years_half):]\n",
    "        train_years = [year for year in years if year not in valid_years]\n",
    "\n",
    "        #generate valid and train dfs\n",
    "        df_valid = self.df[self.df[\"year\"].isin(valid_years)]\n",
    "        df_train =self.df[self.df[\"year\"].isin(train_years)]\n",
    "\n",
    "        #generate x and y\n",
    "        self.X_train = df_train.drop(labels = self.y_col, axis = 1)\n",
    "        self.y_train = df_train[self.y_col]\n",
    "\n",
    "        self.X_valid = df_valid.drop(labels = self.y_col, axis = 1)\n",
    "        self.y_valid = df_valid[self.y_col]\n",
    "\n",
    "        del df_valid, df_train, valid_years, train_years #free up memory\n",
    "\n",
    "        return\n",
    "\n",
    "    def __prep_test_df(self):\n",
    "\n",
    "        #standardize\n",
    "        x_cols = self.df.columns.to_list(); x_cols.remove(self.y_col)\n",
    "        self.df_test[x_cols] = (self.df_test[x_cols] - self.df_unstand[x_cols].mean()) / self.df_unstand[x_cols].std()\n",
    "\n",
    "        #split\n",
    "        self.X_test = self.df_test.drop(labels = self.y_col, axis = 1)\n",
    "        self.y_test = self.df_test[self.y_col]\n",
    "\n",
    "        self.X_test = (self.X_test - self.X_test.mean()) / self.X_test.std()\n",
    "        self.X_test.drop(labels = self.X_test.columns[self.X_test.isna().any()].tolist(), axis = 1, inplace = True)\n",
    "\n",
    "        return\n",
    "\n",
    "    def get_same_guess_accuracy(self):\n",
    "\n",
    "        same_guess_prop_test = [self.y_test.describe()[\"mean\"].round(2), 1 - self.y_test.describe()[\"mean\"].round(2)]\n",
    "        same_guess_prop_valid = [self.y_valid.describe()[\"mean\"].round(2), 1 - self.y_valid.describe()[\"mean\"].round(2)]\n",
    "\n",
    "        self.same_guess_acc = {\n",
    "            \"same_guess_prop_valid\" : same_guess_prop_valid,\n",
    "            \"same_guess_prop_test\" : same_guess_prop_test,\n",
    "        }\n",
    "\n",
    "        print(self.same_guess_acc)\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    def clean_results (self):\n",
    "        \"\"\"Remove all same guess anwsers form the results tabel\"\"\"\n",
    "\n",
    "        self.results[[\"train_score\", \"valid_score\"]] = self.results[[\"train_score\", \"valid_score\"]].round(2)\n",
    "\n",
    "        #same_guess_prop_train = [self.y_train.describe()[\"mean\"].round(2), 1 - self.y_train.describe()[\"mean\"].round(2)]\n",
    "        same_guess_prop_valid = [self.y_valid.describe()[\"mean\"].round(2), 1 - self.y_valid.describe()[\"mean\"].round(2)]\n",
    "\n",
    "        #clean up results df\n",
    "        self.results[\"same_guess\"] = 0\n",
    "        self.results.loc[self.results[\"valid_score\"].isin(same_guess_prop_valid), \"same_guess\"] = 1\n",
    "\n",
    "        self.results = self.results.loc[self.results[\"same_guess\"] != 1].sort_values(by = \"valid_score\", axis = 0, ascending = False)\n",
    "\n",
    "        print(same_guess_prop_valid)\n",
    "\n",
    "        return\n",
    "\n",
    "    def get_single_model_results(self, train_score = None, valid_score = None):\n",
    "\n",
    "        self.model_score = {\n",
    "            \"train\" : train_score,\n",
    "            \"valid\": valid_score,\n",
    "            \"test\" : None\n",
    "        }\n",
    "\n",
    "        if self.df_test is None:\n",
    "            return\n",
    "\n",
    "        #predictions = self.model.predict(self.X_test)\n",
    "        valid_score, valid_acc = self.model.evaluate(self.X_valid, self.y_valid)\n",
    "        test_score, test_acc = self.model.evaluate(self.X_test, self.y_test)\n",
    "\n",
    "        self.single_model_result = {\n",
    "            \"valid_acc\" : round(valid_acc,2),\n",
    "            \"test_acc\" : round(test_acc,2),\n",
    "        }\n",
    "\n",
    "        print(self.single_model_result)\n",
    "        return\n",
    "\n",
    "    def run_optim_child(self):\n",
    "        raise NotImplementedError(\"Must override by calling child class\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "\n",
    "      if(logs.get(\"accuracy\") < 0.001):\n",
    "          print(\"\\nMAEthreshold reached. Training stopped.\")\n",
    "          self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 RNNC Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recurrent neural network classifier liner\n",
    "\n",
    "class RNNC_1(Keras_base):\n",
    "\n",
    "    def run_optim_child(self):\n",
    "\n",
    "        self.early_stopping = EarlyStopping()\n",
    "\n",
    "        for arch in self.architectures:\n",
    "\n",
    "            self.__create_uncompiled_model(arch)\n",
    "            self.__create_model(arch)\n",
    "            print(self.model.summary())\n",
    "            del self.model\n",
    "\n",
    "    def __create_windowed_dataset(self, window_size = 12, batch_size=36, shuffle_buffer=1000):\n",
    "\n",
    "        y = np.array(self.df[self.y_col])\n",
    "\n",
    "        # Extract the feature columns and convert to numpy array.\n",
    "        features = np.array(df.drop(self.y_col, axis=1))\n",
    "\n",
    "        # Create a TensorFlow dataset from the feature and y arrays.\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((features, y))\n",
    "\n",
    "        # Create a windowed dataset.\n",
    "        dataset = dataset.window(window_size, shift=1, drop_remainder=True)\n",
    "        dataset = dataset.flat_map(lambda x, y: tf.data.Dataset.zip((x.batch(window_size), y.batch(window_size))))\n",
    "\n",
    "        # Shuffle and batch the dataset.\n",
    "        dataset = dataset.shuffle(shuffle_buffer).batch(batch_size)\n",
    "\n",
    "        self.dataset = dataset\n",
    "\n",
    "        return\n",
    "\n",
    "    def create_single_model_windowd(self, arch):\n",
    "\n",
    "        self.early_stopping = EarlyStopping()\n",
    "        self.__create_windowed_dataset()\n",
    "        self.__create_uncompiled_model(arch, windowing = True)\n",
    "        self.__create_model(windowing = True)\n",
    "\n",
    "    def create_single_model(self, arch):\n",
    "\n",
    "        self.early_stopping = EarlyStopping()\n",
    "        self.__create_uncompiled_model(arch)\n",
    "        self.__create_model()\n",
    "\n",
    "    def __create_uncompiled_model(self, arch, windowing = False):\n",
    "\n",
    "        #init model and initializer\n",
    "        self.model = tf.keras.models.Sequential()\n",
    "\n",
    "        #add a automaticali scaling input layer\n",
    "        if windowing is False:\n",
    "            shape = [self.n_features]\n",
    "        else:\n",
    "            shape = []\n",
    "\n",
    "        self.model.add(tf.keras.layers.Lambda(\n",
    "            lambda x: tf.expand_dims(x, axis=-1),\n",
    "            input_shape=shape, #working: [None]\n",
    "            #kernel_initializer = self.initializer,\n",
    "            #activation = self.acitvation_func\n",
    "        ))\n",
    "\n",
    "        #add LSTM layers as hidden layers\n",
    "        for i in range(len(arch)):\n",
    "\n",
    "\n",
    "            if (i + 1) == len(arch):\n",
    "                return_sequences = False\n",
    "            else:\n",
    "                return_sequences = True\n",
    "\n",
    "            #hidden layers\n",
    "            self.model.add(tf.keras.layers.Bidirectional(\n",
    "                tf.keras.layers.LSTM(\n",
    "                    arch[i],\n",
    "                    #kernel_initializer = self.initializer,\n",
    "                    activation = self.acitvation_func,\n",
    "                    return_sequences = return_sequences,\n",
    "                )\n",
    "            ))\n",
    "\n",
    "        #add a Dense output layer\n",
    "        self.model.add(tf.keras.layers.Dense(1, activation = self.acitvation_func))\n",
    "\n",
    "        return\n",
    "\n",
    "    def __create_model(self, arch = None, windowing = False):\n",
    "        #see https://keras.io/api/models/model_training_apis/\n",
    "\n",
    "        #compile model\n",
    "        self.model.compile(\n",
    "            loss = self.loss_func,\n",
    "            optimizer = self.solver,\n",
    "            metrics = \"accuracy\" #binary_accuracy\n",
    "        )\n",
    "\n",
    "        #fit model and fetch history\n",
    "        if windowing is False:\n",
    "            self.history = self.model.fit(\n",
    "                x = self.X_train,\n",
    "                y = self.y_train,\n",
    "                validation_data = (self.X_valid,self.y_valid),\n",
    "                shuffle = False, #keep in order because it is time series data\n",
    "                epochs = self.n_epochs,\n",
    "                callbacks =[self.early_stopping]\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            self.history = self.model.fit(\n",
    "                self.dataset,\n",
    "                shuffle = False, #keep in order because it is time series data\n",
    "                epochs = self.n_epochs,\n",
    "                callbacks =[self.early_stopping]\n",
    "            )\n",
    "\n",
    "        #get results and write them\n",
    "        train_accuracy = self.history.history['accuracy'][-1] # binary_accuracy\n",
    "        valid_accuracy = self.history.history[\"val_accuracy\"][-1]\n",
    "\n",
    "        if self.run_optim:\n",
    "            self.save_result(model_type = \"RNNC_SEQ\", train_score = train_accuracy, valid_score = valid_accuracy, arch = arch)\n",
    "        else:\n",
    "            self.get_single_model_results(train_score = train_accuracy, valid_score = valid_accuracy)\n",
    "\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnnc_optim = RNNC_1(\n",
    "\n",
    "    y_col = \"t2m_cat_offset\",\n",
    "    df = df,\n",
    "    df_test = df_test,\n",
    "    run_optim = run_optim,\n",
    "    data_folder = data_folder,\n",
    "    model_splitter = 2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>train_score</th>\n",
       "      <th>valid_score</th>\n",
       "      <th>arch</th>\n",
       "      <th>valid_model_splitter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RNNC_SEQ</td>\n",
       "      <td>0.507576</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>[13]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RNNC_SEQ</td>\n",
       "      <td>0.507576</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>[26]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RNNC_SEQ</td>\n",
       "      <td>0.507576</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>[52]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RNNC_SEQ</td>\n",
       "      <td>0.507576</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>[512]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RNNC_SEQ</td>\n",
       "      <td>0.492424</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>[13, 13]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RNNC_SEQ</td>\n",
       "      <td>0.492424</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>[26, 26]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RNNC_SEQ</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.421687</td>\n",
       "      <td>[52, 52]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RNNC_SEQ</td>\n",
       "      <td>0.507576</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>[512, 256]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RNNC_SEQ</td>\n",
       "      <td>0.517677</td>\n",
       "      <td>0.481928</td>\n",
       "      <td>[13, 13, 13]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RNNC_SEQ</td>\n",
       "      <td>0.507576</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>[26, 26, 26]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RNNC_SEQ</td>\n",
       "      <td>0.507576</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>[52, 52, 52]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RNNC_SEQ</td>\n",
       "      <td>0.507576</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>[512, 256, 128]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RNNC_SEQ</td>\n",
       "      <td>0.494949</td>\n",
       "      <td>0.469880</td>\n",
       "      <td>[13, 13, 13, 13]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RNNC_SEQ</td>\n",
       "      <td>0.507576</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>[26, 26, 26, 26]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RNNC_SEQ</td>\n",
       "      <td>0.507576</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>[52, 52, 52, 52]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RNNC_SEQ</td>\n",
       "      <td>0.482323</td>\n",
       "      <td>0.373494</td>\n",
       "      <td>[512, 256, 128, 64]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RNNC_SEQ</td>\n",
       "      <td>0.469697</td>\n",
       "      <td>0.301205</td>\n",
       "      <td>[13, 13, 13, 13, 13]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RNNC_SEQ</td>\n",
       "      <td>0.507576</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>[26, 26, 26, 26, 26]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RNNC_SEQ</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.385542</td>\n",
       "      <td>[52, 52, 52, 52, 52]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RNNC_SEQ</td>\n",
       "      <td>0.507576</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>[512, 256, 128, 64, 32]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_type  train_score  valid_score                     arch  \\\n",
       "0    RNNC_SEQ     0.507576     0.349398                     [13]   \n",
       "1    RNNC_SEQ     0.507576     0.349398                     [26]   \n",
       "2    RNNC_SEQ     0.507576     0.349398                     [52]   \n",
       "3    RNNC_SEQ     0.507576     0.349398                    [512]   \n",
       "4    RNNC_SEQ     0.492424     0.650602                 [13, 13]   \n",
       "5    RNNC_SEQ     0.492424     0.650602                 [26, 26]   \n",
       "6    RNNC_SEQ     0.472222     0.421687                 [52, 52]   \n",
       "7    RNNC_SEQ     0.507576     0.349398               [512, 256]   \n",
       "8    RNNC_SEQ     0.517677     0.481928             [13, 13, 13]   \n",
       "9    RNNC_SEQ     0.507576     0.349398             [26, 26, 26]   \n",
       "10   RNNC_SEQ     0.507576     0.349398             [52, 52, 52]   \n",
       "11   RNNC_SEQ     0.507576     0.349398          [512, 256, 128]   \n",
       "12   RNNC_SEQ     0.494949     0.469880         [13, 13, 13, 13]   \n",
       "13   RNNC_SEQ     0.507576     0.349398         [26, 26, 26, 26]   \n",
       "14   RNNC_SEQ     0.507576     0.349398         [52, 52, 52, 52]   \n",
       "15   RNNC_SEQ     0.482323     0.373494      [512, 256, 128, 64]   \n",
       "16   RNNC_SEQ     0.469697     0.301205     [13, 13, 13, 13, 13]   \n",
       "17   RNNC_SEQ     0.507576     0.349398     [26, 26, 26, 26, 26]   \n",
       "18   RNNC_SEQ     0.500000     0.385542     [52, 52, 52, 52, 52]   \n",
       "19   RNNC_SEQ     0.507576     0.349398  [512, 256, 128, 64, 32]   \n",
       "\n",
       "    valid_model_splitter  \n",
       "0                      2  \n",
       "1                      2  \n",
       "2                      2  \n",
       "3                      2  \n",
       "4                      2  \n",
       "5                      2  \n",
       "6                      2  \n",
       "7                      2  \n",
       "8                      2  \n",
       "9                      2  \n",
       "10                     2  \n",
       "11                     2  \n",
       "12                     2  \n",
       "13                     2  \n",
       "14                     2  \n",
       "15                     2  \n",
       "16                     2  \n",
       "17                     2  \n",
       "18                     2  \n",
       "19                     2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnnc_optim.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65, 0.35]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>train_score</th>\n",
       "      <th>valid_score</th>\n",
       "      <th>arch</th>\n",
       "      <th>valid_model_splitter</th>\n",
       "      <th>same_guess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RNNC_SEQ</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.48</td>\n",
       "      <td>[13, 13, 13]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RNNC_SEQ</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.47</td>\n",
       "      <td>[13, 13, 13, 13]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RNNC_SEQ</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.42</td>\n",
       "      <td>[52, 52]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RNNC_SEQ</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.39</td>\n",
       "      <td>[52, 52, 52, 52, 52]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RNNC_SEQ</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.37</td>\n",
       "      <td>[512, 256, 128, 64]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RNNC_SEQ</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.30</td>\n",
       "      <td>[13, 13, 13, 13, 13]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_type  train_score  valid_score                  arch  \\\n",
       "8    RNNC_SEQ         0.52         0.48          [13, 13, 13]   \n",
       "12   RNNC_SEQ         0.49         0.47      [13, 13, 13, 13]   \n",
       "6    RNNC_SEQ         0.47         0.42              [52, 52]   \n",
       "18   RNNC_SEQ         0.50         0.39  [52, 52, 52, 52, 52]   \n",
       "15   RNNC_SEQ         0.48         0.37   [512, 256, 128, 64]   \n",
       "16   RNNC_SEQ         0.47         0.30  [13, 13, 13, 13, 13]   \n",
       "\n",
       "    valid_model_splitter  same_guess  \n",
       "8                      2           0  \n",
       "12                     2           0  \n",
       "6                      2           0  \n",
       "18                     2           0  \n",
       "15                     2           0  \n",
       "16                     2           0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnnc_optim.clean_results()\n",
    "rnnc_optim.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13/13 [==============================] - 10s 130ms/step - loss: 7.5958 - accuracy: 0.5076 - val_loss: 10.0355 - val_accuracy: 0.3494\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 1s 40ms/step - loss: 7.5956 - accuracy: 0.5076 - val_loss: 10.0355 - val_accuracy: 0.3494\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 7.5956 - accuracy: 0.5076 - val_loss: 10.0355 - val_accuracy: 0.3494\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 7.5956 - accuracy: 0.5076 - val_loss: 10.0355 - val_accuracy: 0.3494\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 7.5956 - accuracy: 0.5076 - val_loss: 10.0355 - val_accuracy: 0.3494\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 7.5956 - accuracy: 0.5076 - val_loss: 10.0355 - val_accuracy: 0.3494\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 7.5956 - accuracy: 0.5076 - val_loss: 10.0355 - val_accuracy: 0.3494\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 7.5956 - accuracy: 0.5076 - val_loss: 10.0355 - val_accuracy: 0.3494\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 7.5956 - accuracy: 0.5076 - val_loss: 10.0355 - val_accuracy: 0.3494\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 7.5956 - accuracy: 0.5076 - val_loss: 10.0355 - val_accuracy: 0.3494\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 10.0355 - accuracy: 0.3494\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 6.7484 - accuracy: 0.5625\n",
      "{'valid_acc': 0.35, 'test_acc': 0.56}\n"
     ]
    }
   ],
   "source": [
    "rnnc_optim.create_single_model(arch = [13, 13, 13, 13, 13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 9ms/step - loss: 10.0355 - accuracy: 0.3494\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 6.7484 - accuracy: 0.5625\n",
      "{'valid_acc': 0.35, 'test_acc': 0.56}\n"
     ]
    }
   ],
   "source": [
    "rnnc_optim.get_single_model_results()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'same_guess_prop_valid': [0.65, 0.35], 'same_guess_prop_test': [0.44, 0.56]}\n"
     ]
    }
   ],
   "source": [
    "rnnc_optim.get_same_guess_accuracy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings: \n",
    "- The model creates same guess outputs\n",
    "- Not enough data is available for the model to converge"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 RNNC Sequential with shifting Window\n",
    "see https://www.tensorflow.org/tutorials/structured_data/time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnnc_windowd = RNNC_1(\n",
    "    y_col = \"t2m_cat_offset\",\n",
    "    df = df,\n",
    "    df_test = df_test,\n",
    "    run_optim = False,\n",
    "    data_folder = data_folder,\n",
    "    model_splitter = 2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joel hadn't time to implement this or fix the problem\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    rnnc_windowd.create_single_model_windowd(arch = [13, 13, 13, 13, 13])\n",
    "except:\n",
    "    print(\"Joel hadn't time to implement this or fix the problem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 12ms/step - loss: 10.0355 - accuracy: 0.3494\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 6.7484 - accuracy: 0.5625\n",
      "{'valid_acc': 0.35, 'test_acc': 0.56}\n"
     ]
    }
   ],
   "source": [
    "rnnc_optim.get_single_model_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'same_guess_prop_valid': [0.65, 0.35], 'same_guess_prop_test': [0.44, 0.56]}\n"
     ]
    }
   ],
   "source": [
    "rnnc_optim.get_same_guess_accuracy()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6bbfc4e4f578cb9f7c85fe350d2fab0be0faacc19ccc874c1f1be2572a1188f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
