{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from datetime import datetime\n",
    "\n",
    "#folders\n",
    "data_folder = \"data\"\n",
    "\n",
    "#warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set if data should be safed\n",
    "save_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot styles\n",
    "plt_style_c = px.colors.sequential.haline #complex\n",
    "plt_style_s = px.colors.diverging.Portland #simple\n",
    "\n",
    "#defualt plot size \n",
    "size = {\n",
    "    \"width\" : 1500 ,\n",
    "    \"height\" : 750 ,\n",
    "}\n",
    "\n",
    "#function for plotting\n",
    "def scale_show(fig):\n",
    "\n",
    "    #set font\n",
    "    fig.update_layout(\n",
    "        font = dict(size=16),\n",
    "        title_font = dict(size=20),\n",
    "        xaxis_title_font = dict(size=18),\n",
    "        yaxis_title_font = dict(size=18),\n",
    "    )\n",
    "\n",
    "    #set size\n",
    "    fig.update_layout(\n",
    "        width=1500,\n",
    "        height=750,\n",
    "    )\n",
    "\n",
    "    #show\n",
    "    fig.show()\n",
    "\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Main data frame feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_folder, \"df.csv\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up\n",
    "df.drop(labels = [col for col in df.columns.tolist() if \"unnamed\" in col.lower()], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day : int = 24 * 60 * 60 #[sec]\n",
    "year : int = day * 366 #[sec] : 1,\\n2020 was a leap year\n",
    "\n",
    "year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creat col\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"date\"]).apply(datetime.timestamp)\n",
    "\n",
    "#calculate values\n",
    "day : int = 24 * 60 * 60 #[sec]\n",
    "year : int = day * 366 #[sec] : 1,\\n2020 was a leap year\n",
    "\n",
    "#set columns\n",
    "df[\"year_sin\"] = np.sin(df[\"timestamp\"] * (2*np.pi / year))\n",
    "df[\"year_cos\"] = np.cos(df[\"timestamp\"] * (2*np.pi / year))\n",
    "\n",
    "#del unneedec col\n",
    "df.drop(labels = [\"timestamp\"], axis = 1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add wind speed and direction\n",
    "fig = px.line(\n",
    "    data_frame = df.iloc[15000:],\n",
    "    x = \"date\",\n",
    "    y = [\"year_sin\", \"year_cos\"],\n",
    "\n",
    "    title = \"Year sine and cosine\",\n",
    "    color_discrete_sequence = plt_style_s,\n",
    ")\n",
    "\n",
    "scale_show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add rolling mean for ao, soi, t2m\n",
    "\n",
    "cols_rolling_mean = [\"soi\", \"ao\", \"mjo_amplitude\", \"t2m\", \"nao\"]\n",
    "offset = 30 #days\n",
    "\n",
    "for col in cols_rolling_mean:\n",
    "\n",
    "    #get rolling mean\n",
    "    col_name = f\"ma_{col}\"\n",
    "    df[col_name] = df[col].rolling(offset).mean()\n",
    "\n",
    "    #create plot\n",
    "    fig = px.line(\n",
    "        data_frame = df[15000:],\n",
    "        y = [col, col_name],\n",
    "        x = \"date\",\n",
    "        title = f\"Moving average: {col}\",\n",
    "        color_discrete_sequence = plt_style_s\n",
    "    )\n",
    "\n",
    "    scale_show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add wind speed\n",
    "df['wind_speed'] = np.sqrt(df['u10']**2 + df['v10']**2)\n",
    "\n",
    "#add wind direction\n",
    "df['wind_direction'] = np.rad2deg(np.arctan2(df['u10'], df['v10'])) % 360\n",
    "df['wind_direction'] = (df['wind_direction'] + 90) % 360\n",
    "\n",
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    data_frame = df,\n",
    "    x = \"wind_direction\",\n",
    "    histnorm = \"probability density\",\n",
    "    title = \"Wind direction\",\n",
    " \n",
    "    color = \"month\",\n",
    "    barmode = \"stack\",\n",
    "    opacity = 1,\n",
    "\n",
    "    nbins = 180,\n",
    "\n",
    "    labels = {\"wind_direction\" : \"wind direction [Â°]\"},\n",
    "\n",
    "    color_discrete_sequence = plt_style_c,\n",
    ")\n",
    "\n",
    "scale_show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    data_frame = df,\n",
    "    x = \"wind_speed\",\n",
    "    histnorm = \"probability density\",\n",
    "    title = \"wind_speed\",\n",
    " \n",
    "    color = \"month\",\n",
    "    barmode = \"stack\",\n",
    "    opacity = 1,\n",
    "\n",
    "    nbins = 180,\n",
    "\n",
    "    labels = {\"wind_speed\" : \"wind speed [m/s]\"},\n",
    "\n",
    "    color_discrete_sequence = plt_style_c,\n",
    ")\n",
    "\n",
    "scale_show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add peak identifiers for mjo, ao, soi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(keys = \"date\", inplace = True)\n",
    "\n",
    "if save_data:\n",
    "    df.to_csv(os.path.join(data_folder, \"df_fe.csv\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Polar vortex index engineering\n",
    "\n",
    "read some: https://www.severe-weather.eu/global-weather/strong-polar-vortex-warming-collapse-event-forecast-spring-2022-usa-europe-fa/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analyzing patterns during break down events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_folder, \"df_pv.csv\"))\n",
    "#df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df[\"size\"] = 1\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interpolate preassure levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interplolate data for plotting\n",
    "missing_levels = [40,60,80,90]\n",
    "\n",
    "dates   = df[\"date\"].unique()\n",
    "lons    = df[\"longitude\"].unique()\n",
    "lats    = df[\"latitude\"].unique()\n",
    "lvls    = missing_levels\n",
    "\n",
    "interpolation_data = {\n",
    "    \"date\"          :[],\n",
    "    \"longitude\"     :[],\n",
    "    \"latitude\"      :[],\n",
    "    \"level\"         :[],\n",
    "}\n",
    "\n",
    "#ugly and inefficient code\n",
    "\n",
    "for date in dates:\n",
    "    for lon in lons:\n",
    "        for lat in lats:\n",
    "            for lvl in lvls:\n",
    "\n",
    "                interpolation_data[\"date\"].append(date)\n",
    "                interpolation_data[\"longitude\"].append(lon)\n",
    "                interpolation_data[\"latitude\"].append(lat)\n",
    "                interpolation_data[\"level\"].append(lvl)\n",
    "\n",
    "df_int = pd.DataFrame(interpolation_data)\n",
    "df_int.head()\n",
    "\n",
    "#merge dfs\n",
    "df = pd.concat(objs = [df, df_int])\n",
    "df.sort_values(by = [\"date\", \"longitude\", \"latitude\", \"level\"], inplace = True, axis = 0)\n",
    "\n",
    "#clean up\n",
    "df.reset_index(inplace = True)\n",
    "\n",
    "#interpolate values\n",
    "\n",
    "df[\"interpolated\"] = 0\n",
    "df.loc[df[\"level\"].isin(missing_levels), \"interpolated\"] = 1\n",
    "\n",
    "df.interpolate(metohd = \"linear\", inplace = True)\n",
    "\n",
    "#recalculate speed and dircetion for interpolated values\n",
    "\n",
    "#speed\n",
    "df.loc[df[\"interpolated\"] == 1, \"speed\"] = np.sqrt(df[\"u\"] ** 2 + df[\"v\"] ** 2)\n",
    "\n",
    "df.loc[df[\"interpolated\"] == 1, 'direction'] = np.rad2deg(np.arctan2(df['u'], df['v'])) % 360\n",
    "df.loc[df[\"interpolated\"] == 1, 'direction'] = (df['direction'] + 90) % 360\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_data is True:\n",
    "    df_pv_clustering = df[[\"date\", \"longitude\", \"latitude\", \"level\", \"t\", \"speed\"]].loc[df[\"longitude\"] == 8]\n",
    "    df_pv_clustering.set_index(\"date\", drop = True, inplace = True)\n",
    "    df_pv_clustering.to_csv(os.path.join(data_folder, \"df_pv_clustering.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scaler = 20\n",
    "fig = px.scatter(\n",
    "    data_frame = df.loc[(df[\"date\"] >= \"2019-03-01\") & (df[\"date\"] <= \"2019-03-04\")],\n",
    "    y = \"level\",\n",
    "    x = \"latitude\",\n",
    "    color = \"speed\",\n",
    "    size = \"size\",\n",
    "    size_max = 1 * plot_scaler - 1,\n",
    "    opacity = 1,\n",
    "    facet_row = \"date\",\n",
    "    #animation_frame = \"date\",\n",
    "\n",
    "    height = (15 * 4)  * plot_scaler,\n",
    "    width = 60 * plot_scaler,\n",
    "    color_continuous_scale =  plt_style_s,\n",
    "\n",
    "    title = \"Polar vortex wind speed\",\n",
    "\n",
    "    labels = {\"speed\" : \"speed [m/s]\"},\n",
    ")\n",
    "\n",
    "fig['layout']['yaxis']['autorange'] = \"reversed\"\n",
    "\n",
    "fig.update_traces(\n",
    "    marker=dict(symbol=\"square\",),\n",
    "    selector=dict(mode='markers')\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scaler = 20\n",
    "fig = px.scatter(\n",
    "    data_frame = df.loc[(df[\"date\"] >= \"2019-03-01\") & (df[\"date\"] <= \"2019-03-04\")],\n",
    "    y = \"level\",\n",
    "    x = \"latitude\",\n",
    "    color = \"t\",\n",
    "    size = \"size\",\n",
    "    size_max = 1 * plot_scaler - 1,\n",
    "    opacity = 1,\n",
    "    facet_row = \"date\",\n",
    "    #animation_frame = \"date\",\n",
    "\n",
    "    height = (15 * 4)  * plot_scaler,\n",
    "    width = 60 * plot_scaler,\n",
    "    color_continuous_scale =  plt_style_s,\n",
    "\n",
    "    title = \"Polar vortex temperature\",\n",
    "\n",
    "    labels = {\"t\" : \"t [kÂ°]\"},\n",
    ")\n",
    "\n",
    "fig['layout']['yaxis']['autorange'] = \"reversed\"\n",
    "\n",
    "fig.update_traces(\n",
    "    marker=dict(symbol=\"square\",),\n",
    "    selector=dict(mode='markers')\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop latitude 90. Looks like a cut in the data\n",
    "df.drop(df.loc[df[\"latitude\"] == 90].index, inplace = True)\n",
    "\n",
    "\n",
    "plot_scaler = 20\n",
    "fig = px.scatter(\n",
    "    data_frame = df.loc[(df[\"date\"] >= \"1979-01-23\") & (df[\"date\"] <= \"1979-01-30\")],\n",
    "    y = \"level\",\n",
    "    x = \"latitude\",\n",
    "    color = \"speed\",\n",
    "    size = \"size\",\n",
    "    size_max = 1 * plot_scaler - 1,\n",
    "    opacity = 1,\n",
    "    facet_row = \"date\",\n",
    "    #animation_frame = \"date\",\n",
    "\n",
    "    height = (20 * 6)  * plot_scaler,\n",
    "    width = 60 * plot_scaler,\n",
    "    color_continuous_scale =  plt_style_s,\n",
    "\n",
    "    title = \"Polar vortex wind speed\",\n",
    "\n",
    "    labels = {\"speed\" : \"speed [m/s]\"},\n",
    ")\n",
    "\n",
    "fig['layout']['yaxis']['autorange'] = \"reversed\"\n",
    "\n",
    "fig.update_traces(\n",
    "    marker=dict(symbol=\"square\",),\n",
    "    selector=dict(mode='markers')\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Costuom index 1 (wind speed only)\n",
    " - Convolution on lattitide level (vertical bar with pieces)\n",
    " - Detect border of vortex by wind speeds (get most constant latitude by std, invert it, multiply by wind speed)\n",
    " - value_0 = border_height (0 .. n, 0 = switzerland, n = north pole)\n",
    " - value_1 = temperature  at height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pv_i1_w(df):\n",
    "\n",
    "    #drop unneded cols\n",
    "    df_i1 = df[[\"date\", \"latitude\", \"t\", \"speed\"]]\n",
    "\n",
    "    #crate latitude aggregation\n",
    "    df_i1 = df_i1.groupby(by = [\"date\", \"latitude\"], as_index = False).aggregate(\n",
    "        speed_mean = (\"speed\", \"mean\"),\n",
    "        speed_std = (\"speed\", \"std\"),\n",
    "        t_mean =    (\"t\", \"mean\"),\n",
    "    )\n",
    "\n",
    "    #normalize the standard deviation\n",
    "    # source: https://business.blogthinkbig.com/warning-about-normalizing-data/\n",
    "\n",
    "    #get local min and max\n",
    "    df_i1_minmax = df_i1[[\"date\", \"speed_std\"]]\n",
    "    df_i1_minmax = df_i1_minmax.groupby(by = [\"date\"], as_index = False).aggregate(\n",
    "        speed_std_max = (\"speed_std\", \"max\"),\n",
    "        speed_std_min = (\"speed_std\", \"min\"),\n",
    "    )\n",
    "\n",
    "    #append data together\n",
    "    df_i1[\"date\"] = df_i1[\"date\"].astype(str)\n",
    "    df_i1_minmax[\"date\"] = df_i1_minmax[\"date\"].astype(str)\n",
    "\n",
    "    df_i1[\"date\"] = pd.to_datetime(df_i1[\"date\"])\n",
    "    df_i1_minmax[\"date\"] = pd.to_datetime(df_i1_minmax[\"date\"])\n",
    "\n",
    "    df_i1 = df_i1.merge(right = df_i1_minmax, on = \"date\", how = \"left\")\n",
    "\n",
    "    #calculate normalized std\n",
    "    df_i1[\"speed_norm_inv\"] = 1 - (df_i1[\"speed_std\"] - df_i1[\"speed_std_min\"]) / (df_i1[\"speed_std_max\"] - df_i1[\"speed_std_min\"])\n",
    "\n",
    "    #calculate weighted wind speed \n",
    "    df_i1[\"speed_weight\"] = df_i1[\"speed_mean\"] * df_i1[\"speed_norm_inv\"]\n",
    "\n",
    "    #get local max and min for index based on date\n",
    "    df_i1_max = df_i1[[\"date\", \"speed_weight\"]].groupby(by = \"date\", as_index = False).max()\n",
    "    df_i1_max[\"is_max\"] = 1\n",
    "\n",
    "    #get the lattitude at max\n",
    "    df_i1 = df_i1.merge(right = df_i1_max, on = [\"date\", \"speed_weight\"], how = \"left\")\n",
    "    df_i1 = df_i1.loc[df_i1[\"is_max\"] == 1]\n",
    "\n",
    "    #clean up\n",
    "    df_i1 = df_i1[[\"date\", \"latitude\", \"t_mean\"]]\n",
    "    df_i1_w = df_i1; del df_i1\n",
    "\n",
    "    return df_i1_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i1_w = pv_i1_w(df)\n",
    "df_i1_w.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_i1(df, df_i1, plot_param):\n",
    "\n",
    "    dates = [\n",
    "        \"2019-03-01\", \"2019-03-02\", \"2019-03-03\", \"2019-03-04\"\n",
    "        #\"1979-04-01\",\"1979-05-01\",\"1979-06-01\",\n",
    "        #\"1979-07-01\",\"1979-08-01\",\"1979-09-01\",\n",
    "        #\"1979-10-01\",\"1979-11-01\",\"1979-12-01\",\n",
    "    ]\n",
    "\n",
    "    if plot_param == \"t\":\n",
    "        title = \"temperature\"\n",
    "        widht_correction = 2\n",
    "    elif plot_param == \"speed\":\n",
    "        title = \"wind speed\"\n",
    "        widht_correction = 4\n",
    "\n",
    "    for date in dates:\n",
    "\n",
    "        plot_scaler = 20\n",
    "\n",
    "        fig = px.scatter(\n",
    "            data_frame = df.loc[df[\"date\"] == date],\n",
    "            x = \"latitude\",\n",
    "            y = \"level\",\n",
    "            color = plot_param,\n",
    "            size = \"size\",\n",
    "            size_max = 1 * plot_scaler -7,\n",
    "            opacity = 1,\n",
    "            facet_col = \"date\",\n",
    "            #animation_frame = \"date\",\n",
    "\n",
    "            height = 20  * plot_scaler,\n",
    "            width = 60 * plot_scaler,\n",
    "            color_continuous_scale =  plt_style_s,\n",
    "\n",
    "\n",
    "            title = f\"Polar vortex {title}\",\n",
    "\n",
    "            labels = {\"speed\" : \"speed [m/s]\"},\n",
    "        )\n",
    "\n",
    "        fig.update_traces(\n",
    "            marker=dict(symbol=\"square\",),\n",
    "            selector=dict(mode='markers')\n",
    "        )\n",
    "\n",
    "        #indicator\n",
    "        x = float(df_i1.loc[df_i1[\"date\"] == date][\"latitude\"])\n",
    "        \n",
    "        fig.add_vline(\n",
    "            x = x\n",
    "        )\n",
    "\n",
    "        #reverse axis\n",
    "        fig['layout']['yaxis']['autorange'] = \"reversed\"\n",
    "\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_i1(df, df_i1_w, \"t\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Costuom index 1 (wind speed + tempereautre)\n",
    " - Convolution on lattitide level (vertical bar with pieces)\n",
    " - Detect border of vortex by wind speeds and temperature (get most constant latitude by std, invert it, multiply by wind speed)\n",
    " - value_0 = border_height (0 .. n, 0 = switzerland, n = north pole)\n",
    " - value_1 = temperature  at height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pv_i1_wt(df, speed_weight = 0.3, t_weight = 0.7):\n",
    "\n",
    "    #drop unneded cols\n",
    "    df_i1 = df[[\"date\", \"latitude\", \"t\", \"speed\"]]\n",
    "\n",
    "    #crate latitude aggregation\n",
    "    df_i1 = df_i1.groupby(by = [\"date\", \"latitude\"], as_index = False).aggregate(\n",
    "        speed_mean = (\"speed\", \"mean\"),\n",
    "        speed_std = (\"speed\", \"std\"),\n",
    "        t_mean =    (\"t\", \"mean\"),\n",
    "    )\n",
    "\n",
    "    #normalize the standard deviation\n",
    "    # source: https://business.blogthinkbig.com/warning-about-normalizing-data/\n",
    "\n",
    "    #get local min and max\n",
    "    df_i1_minmax = df_i1[[\"date\", \"speed_std\", \"t_mean\"]]\n",
    "    df_i1_minmax = df_i1_minmax.groupby(by = [\"date\"], as_index = False).aggregate(\n",
    "        speed_std_max   = (\"speed_std\", \"max\"),\n",
    "        speed_std_min   = (\"speed_std\", \"min\"),\n",
    "        t_mean_max      = (\"t_mean\", \"max\"),\n",
    "        t_mean_min      = (\"t_mean\", \"min\"),\n",
    "    )\n",
    "\n",
    "    #append data together\n",
    "    df_i1[\"date\"] = df_i1[\"date\"].astype(str)\n",
    "    df_i1_minmax[\"date\"] = df_i1_minmax[\"date\"].astype(str)\n",
    "\n",
    "    df_i1[\"date\"] = pd.to_datetime(df_i1[\"date\"])\n",
    "    df_i1_minmax[\"date\"] = pd.to_datetime(df_i1_minmax[\"date\"])\n",
    "\n",
    "    df_i1 = df_i1.merge(right = df_i1_minmax, on = \"date\", how = \"left\")\n",
    "\n",
    "    #calculate normalized std\n",
    "    df_i1[\"speed_norm_inv\"] = 1 - (df_i1[\"speed_std\"] - df_i1[\"speed_std_min\"]) / (df_i1[\"speed_std_max\"] - df_i1[\"speed_std_min\"])\n",
    "    df_i1[\"t_norm_inv\"] = 1 - (df_i1[\"t_mean\"] - df_i1[\"t_mean_min\"]) / (df_i1[\"t_mean_max\"] - df_i1[\"t_mean_min\"])\n",
    "\n",
    "    #calculate weighted wind speed\n",
    "    df_i1[\"weight\"] = df_i1[\"speed_mean\"] * (df_i1[\"speed_norm_inv\"] * speed_weight + df_i1[\"t_norm_inv\"] * t_weight)\n",
    "\n",
    "    #get local max and min for index based on date\n",
    "    df_i1_max = df_i1[[\"date\", \"weight\"]].groupby(by = \"date\", as_index = False).max()\n",
    "    df_i1_max[\"is_max\"] = 1\n",
    "\n",
    "    #get the lattitude at max\n",
    "    df_i1 = df_i1.merge(right = df_i1_max, on = [\"date\", \"weight\"], how = \"left\")\n",
    "    df_i1 = df_i1.loc[df_i1[\"is_max\"] == 1]\n",
    "\n",
    "    #clean up\n",
    "    df_i1 = df_i1[[\"date\", \"latitude\", \"t_mean\"]]\n",
    "    df_i1_wt = df_i1; del df_i1\n",
    "\n",
    "    return df_i1_wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i1_wt = pv_i1_wt(df)\n",
    "df_i1_wt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_i1(df, df_i1_wt, \"speed\") #\"speed\", \"t\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_i1_w, df_i1_wt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Custom index 2 (edge detection):\n",
    " - detect sharp borders of temperature changes\n",
    " - create a contrast values accors n vertical rows\n",
    " - detect sharpest border, based on threshold\n",
    " - if no value recheas the threshold, a breakdown can be detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom index idea 2:\n",
    "# - detect sharp borders of temperature changes\n",
    "# - create a contrast values accors n vertical rows\n",
    "# - detect sharpest border, based on threshold\n",
    "# - if no value recheas the threshold, a breakdown can be detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PV_ind_2_v2():\n",
    "\n",
    "    def main(df, n_lat, threshold, break_down_offset, break_down_sensitivity, metric):\n",
    "        \"\"\"metric: [\"t\", \"speed\"]\"\"\"\n",
    "\n",
    "        df_i2 = PV_ind_2_v2.get_delta(df, n_lat, metric)\n",
    "        df_i2 = PV_ind_2_v2.get_local_max_delta(df_i2)\n",
    "        df_i2 = PV_ind_2_v2.apply_threshold(df_i2, threshold)\n",
    "        df_i2 = PV_ind_2_v2.detect_breakdown(df_i2, break_down_offset, break_down_sensitivity)\n",
    "\n",
    "        return df_i2\n",
    "\n",
    "    def get_delta(df, n, metric):\n",
    "\n",
    "        #drop unneded cols\n",
    "        df_i2 = df[[\"date\", \"latitude\", \"t\", \"speed\"]]\n",
    "        del df\n",
    "\n",
    "        #crate latitude aggregation\n",
    "        df_i2 = df_i2.groupby(by = [\"date\", \"latitude\"], as_index = False).aggregate(\n",
    "            speed_mean  = (\"speed\", \"mean\"),\n",
    "            #speed_std   = (\"speed\", \"std\"),\n",
    "            t_mean      = (\"t\", \"mean\"),\n",
    "            #t_std       = (\"t\", \"std\"),\n",
    "        )\n",
    "\n",
    "        df_i2.sort_values(by = [\"date\", \"latitude\"], ascending = [True , False], inplace = True)\n",
    "\n",
    "        #create offshift for border detection\n",
    "        cols = [f\"{metric}_mean\"]\n",
    "\n",
    "        for i in range(1, n+1):\n",
    "            df_i2[f\"{metric}_mean_-{i}\"] = df_i2[f\"{metric}_mean\"].shift(-i)\n",
    "            cols.append(f\"{metric}_mean_{-i}\")\n",
    "\n",
    "        #create deltas for border detection (square values to only get positive values and highlight bigger deltas)\n",
    "        cols_delta = []\n",
    "        for i in range(n):\n",
    "            df_i2[f\"delta_{i}\"] = abs(df_i2[cols[i]] - df_i2[cols[i + 1]])\n",
    "            cols_delta.append(f\"delta_{i}\")\n",
    "\n",
    "        #sum deltas to get border value\n",
    "        df_i2[\"delta\"] = df_i2[cols_delta].mean(axis=1)\n",
    "\n",
    "        #drop lower n cols\n",
    "        lats = df_i2[\"latitude\"].unique()\n",
    "        lats.sort()\n",
    "        lats = lats[:n]\n",
    "\n",
    "        df_i2.loc[df_i2[\"latitude\"].isin(lats), \"delta\"] = None\n",
    "\n",
    "        #clean up\n",
    "        df_i2.drop(labels = cols[1:] + cols_delta, axis = 1, inplace = True)\n",
    "\n",
    "        return df_i2\n",
    "\n",
    "    def get_local_max_delta(df_i2):\n",
    "        \n",
    "        #get max values\n",
    "        df_i2_max = df_i2[[\"date\", \"delta\"]].groupby(by = [\"date\"], as_index = False).max()\n",
    "        df_i2_max[\"is_max\"] = 1\n",
    "\n",
    "        #set max in master df\n",
    "        df_i2 = df_i2.merge(right = df_i2_max, on = [\"date\", \"delta\"], how = \"left\")\n",
    "        #df_i2[\"is_max\"] = df_i2[\"is_max\"].fillna(0)\n",
    "        #df_i2[\"is_max\"] = df_i2[\"is_max\"].astype(int)\n",
    "\n",
    "        #clean up\n",
    "        del df_i2_max\n",
    "        return df_i2\n",
    "\n",
    "    def apply_threshold(df_i2, threshold):\n",
    "\n",
    "        #set th as multiplicator\n",
    "        th = threshold + 1\n",
    "\n",
    "        #get mean\n",
    "        df_i2_d = df_i2[[\"date\",\"delta\"]].groupby(by = \"date\", as_index = False).aggregate(\n",
    "            mean_delta = (\"delta\", \"mean\"),\n",
    "        )\n",
    "\n",
    "        #combine and apply th\n",
    "        df_i2 = df_i2.merge(right = df_i2_d, on = \"date\", how = \"left\")\n",
    "        df_i2[\"mean_delta\"] = df_i2[\"mean_delta\"] * th\n",
    "\n",
    "        #compare\n",
    "        df_i2[\"pv_edge\"] = 0\n",
    "        df_i2.loc[(df_i2[\"is_max\"] == 1) & (df_i2[\"delta\"] > df_i2[\"mean_delta\"]), \"pv_edge\"] = 1\n",
    "\n",
    "        #clean up\n",
    "        df_i2.dropna(subset = \"is_max\", inplace = True)\n",
    "        df_i2.drop(labels = [\"is_max\"], axis = 1, inplace = True)\n",
    "\n",
    "        return df_i2\n",
    "\n",
    "    def detect_breakdown(df_i2, break_down_offset, break_down_sensitivity):\n",
    "\n",
    "        #considered months\n",
    "        considered_months = [12,1,2,3,4]\n",
    "        df_i2[\"date\"] = pd.to_datetime(df_i2[\"date\"])\n",
    "\n",
    "        #consider offset by applying rolling mean.\n",
    "        df_i2[\"pv_edge_offset\"] = df_i2[\"pv_edge\"].rolling(break_down_offset).mean()\n",
    "\n",
    "        #break down event\n",
    "\n",
    "        df_i2[\"pv_break_down_event\"] = 0\n",
    "        df_i2.loc[\n",
    "            (df_i2[\"pv_edge_offset\"] <= break_down_sensitivity) &\n",
    "            (df_i2[\"pv_edge_offset\"].shift(1) > break_down_sensitivity) &\n",
    "            (df_i2[\"date\"].dt.month.isin(considered_months))\n",
    "            , \"pv_break_down_event\"] = 1\n",
    "\n",
    "        #clean up\n",
    "        df_i2.drop(labels = \"pv_edge_offset\", axis = 1, inplace = True)\n",
    "\n",
    "        return df_i2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params\n",
    "n_lat                   = 3 #lat offset for calultion\n",
    "threshold               = 1 #in % for vortex, multiple which has to be exceeded from popluation mean, to be counted as a pv edge\n",
    "break_down_offset       = 3 #last n span, used to detect a break down\n",
    "break_down_sensitivity  = 0.1 # in %. Sets the barrier or threshold, at which the value crossing it, a breakdown will be detected\n",
    "\n",
    "df_i2_s = PV_ind_2_v2.main(\n",
    "    df = df,\n",
    "    n_lat = n_lat,\n",
    "    threshold = threshold,\n",
    "    break_down_offset = break_down_offset,\n",
    "    break_down_sensitivity = break_down_sensitivity,\n",
    "    metric = \"speed\",\n",
    ")\n",
    "\n",
    "df_i2_s.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params\n",
    "n_lat                   = 2 #lat offset for calultion\n",
    "threshold               = 1 #in % for vortex, multiple which has to be exceeded from popluation mean, to be counted as a pv edge\n",
    "break_down_offset       = 3 #last n span, used to detect a break down\n",
    "break_down_sensitivity  = 0.1 # in %. Sets the barrier or threshold, at which the value crossing it, a breakdown will be detected\n",
    "\n",
    "df_i2_t = PV_ind_2_v2.main(\n",
    "    df = df,\n",
    "    n_lat = n_lat,\n",
    "    threshold = threshold,\n",
    "    break_down_offset = break_down_offset,\n",
    "    break_down_sensitivity = break_down_sensitivity,\n",
    "    metric = \"t\",\n",
    ")\n",
    "\n",
    "df_i2_t.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_i2(df, df_i, plot_param, dates = None):\n",
    "\n",
    "    if dates is None:\n",
    "\n",
    "        dates = [\n",
    "            \"2019-03-01\", \"2019-03-02\", \"2019-03-03\", \"2019-03-04\", \"2019-03-05\",\n",
    "            #\"2022-04-01\",\"2022-05-01\",\"2022-06-01\",\n",
    "            #\"2022-07-01\",\"2022-08-01\",\"2022-09-01\",\n",
    "            #\"2022-10-01\",\"2022-11-01\",\"2022-12-01\",\n",
    "        ]\n",
    "\n",
    "    if plot_param == \"t\":\n",
    "        title = \"temperature\"\n",
    "        color_bounds = [190, 230]\n",
    "    elif plot_param == \"speed\":\n",
    "        title = \"wind speed\"\n",
    "        color_bounds = [0, 50]\n",
    "\n",
    "    for date in dates:\n",
    "\n",
    "        plot_scaler = 20\n",
    "\n",
    "        fig = px.scatter(\n",
    "            data_frame = df.loc[df[\"date\"] == date],\n",
    "            x = \"latitude\",\n",
    "            y = \"level\",\n",
    "            color = plot_param,\n",
    "            size = \"size\",\n",
    "            size_max = 1 * plot_scaler - 3,\n",
    "            opacity = 1,\n",
    "            facet_col = \"date\",\n",
    "            #animation_frame = \"date\",\n",
    "            range_color = color_bounds,\n",
    "\n",
    "            height = 20  * plot_scaler,\n",
    "            width = 60 * plot_scaler,\n",
    "            color_continuous_scale  = plt_style_s,\n",
    "\n",
    "            title = f\"Polar vortex: {title}\",\n",
    "\n",
    "            labels = {\"speed\" : \"speed [m/s]\", \"t\" : \"t [Â°k]\"},\n",
    "        )\n",
    "\n",
    "        fig.update_traces(\n",
    "            marker=dict(symbol=\"square\",),\n",
    "            selector=dict(mode='markers')\n",
    "        )\n",
    "\n",
    "        #indicator\n",
    "        x = float(df_i.loc[df_i[\"date\"] == date][\"latitude\"])\n",
    "        #th_exceeded = int(df_i1.loc[df_i1[\"date\"] == date][\"pv_edge\"])\n",
    "\n",
    "        fig['layout']['yaxis']['autorange'] = \"reversed\"\n",
    "\n",
    "        fig.add_vline(\n",
    "            x = x,\n",
    "            #line_color = \"black\",\n",
    "            #line_width = th_exceeded * 5,\n",
    "        )\n",
    "\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_i2(df, df_i2_s, \"speed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_i2(df, df_i2_t, \"t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(\n",
    "    data_frame = df_i2_s.iloc[-5000:],\n",
    "    x = \"date\",\n",
    "    y = \"pv_break_down_event\",\n",
    "\n",
    "    title = \"Polar vortex edge detection\",\n",
    "    color_discrete_sequence = plt_style_s,\n",
    ")\n",
    "\n",
    "scale_show(fig)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom index 3 (delta index):\n",
    " - convolution of data at each end with weighted mean, based on distance (twice, one for wind speed, and one for temperature)\n",
    " - get delta of the area as a single value for each metric from the two obainted values\n",
    " - or leave the two values as they are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PV_ind_3():\n",
    "\n",
    "    def main(df, metric):\n",
    "\n",
    "        df_i3 = PV_ind_3.agg(df, metric)\n",
    "        df_i3 = PV_ind_3.set_weights(df_i3)\n",
    "        df_i3 = PV_ind_3.normalize_metric(df_i3, metric)\n",
    "        df_i3 = PV_ind_3.set_p_values(df_i3, metric)\n",
    "\n",
    "        return df_i3\n",
    "\n",
    "    def agg(df, metric):\n",
    "\n",
    "        #aggreagte data\n",
    "        df_i3 = df[[\"date\", \"latitude\", metric]].groupby(by = [\"date\", \"latitude\"], as_index = False).mean()\n",
    "        #df_i3.rename(mapper = {metric : \"metric\"}, inplace = True, axis = 1)\n",
    "\n",
    "        return df_i3\n",
    "\n",
    "    def normalize_metric(df_i3, metric):\n",
    "\n",
    "        #get local min and max\n",
    "        df_i3_minmax = df_i3[[\"date\", metric]]\n",
    "        df_i3_minmax = df_i3_minmax.groupby(by = \"date\").aggregate(\n",
    "            metric_max      = (metric, \"max\"),\n",
    "            metric_min      = (metric, \"min\"),\n",
    "        )\n",
    "\n",
    "        #append data together\n",
    "        df_i3 = df_i3.merge(right = df_i3_minmax, on = \"date\", how = \"left\")\n",
    "\n",
    "        #calculated normalized metric\n",
    "        df_i3[f\"{metric}_norm\"] = (df_i3[metric] - df_i3[\"metric_min\"]) / (df_i3[\"metric_max\"] - df_i3[\"metric_min\"])\n",
    "\n",
    "        #clean up\n",
    "        df_i3.drop(labels = [\"metric_max\", \"metric_min\"], axis = 1, inplace = True)\n",
    "\n",
    "        return df_i3\n",
    "\n",
    "    def set_weights(df_i3):\n",
    "\n",
    "        #transform\n",
    "        min_lat = float(df_i3[\"latitude\"].min())\n",
    "        df_i3[\"weight_n\"] = df_i3[\"latitude\"] - min_lat\n",
    "\n",
    "        #transform to values between 0 and 1\n",
    "        max_lat = float(df_i3[\"latitude\"].max())\n",
    "\n",
    "        df_i3[\"weight_n\"] = df_i3[\"weight_n\"] / max_lat\n",
    "        df_i3[\"weight_s\"] = 1 - df_i3[\"weight_n\"]\n",
    "\n",
    "        return df_i3\n",
    "\n",
    "    def set_p_values(df_i3, metric):\n",
    "\n",
    "        #get p_value\n",
    "        df_i3[\"p_north\"] = df_i3[f\"{metric}_norm\"] * df_i3[\"weight_n\"]\n",
    "        df_i3[\"p_south\"] = df_i3[f\"{metric}_norm\"] * df_i3[\"weight_s\"]\n",
    "\n",
    "        #get sum\n",
    "        df_i3.drop(labels = [metric, \"weight_n\", \"weight_s\", f\"{metric}_norm\", \"latitude\"], axis = 1, inplace = True)\n",
    "        df_i3 = df_i3.groupby(by = [\"date\"], as_index = False).sum()\n",
    "\n",
    "        #get delta\n",
    "        df_i3[\"p_delta\"] = df_i3[\"p_south\"] - df_i3[\"p_north\"]\n",
    "\n",
    "        return df_i3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i3 = PV_ind_3.main(df, metric = \"t\")\n",
    "df_i3.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_i3(df, df_i3, plot_param):\n",
    "\n",
    "    dates = [\n",
    "        \"2019-03-01\", \"2019-03-02\", \"2019-03-03\", \"2019-03-04\",\n",
    "        #\"2022-04-01\",\"2022-05-01\",\"2022-06-01\",\n",
    "        #\"2022-07-01\",\"2022-08-01\",\"2022-09-01\",\n",
    "        #\"2022-10-01\",\"2022-11-01\",\"2022-12-01\",\n",
    "    ]\n",
    "\n",
    "    if plot_param == \"t\":\n",
    "        title = \"temperature\"\n",
    "        widht_correction = 2\n",
    "    elif plot_param == \"speed\":\n",
    "        title = \"wind speed\"\n",
    "        widht_correction = 4\n",
    "\n",
    "\n",
    "    for date in dates:\n",
    "\n",
    "        plot_scaler = 19\n",
    "\n",
    "        #indicator\n",
    "        p_delta = round(float(df_i3.loc[df_i3[\"date\"] == date][\"p_delta\"]),2)\n",
    "\n",
    "        fig = px.scatter(\n",
    "            data_frame = df.loc[df[\"date\"] == date],\n",
    "            x = \"latitude\",\n",
    "            y = \"level\",\n",
    "            color = plot_param,\n",
    "            size = \"size\",\n",
    "            size_max = 1 * plot_scaler - 3,\n",
    "            opacity = 1,\n",
    "            facet_col = \"date\",\n",
    "            #animation_frame = \"date\",\n",
    "\n",
    "            height = 20 * plot_scaler,\n",
    "            width = 60 * plot_scaler,\n",
    "            color_continuous_scale  = plt_style_s,\n",
    "\n",
    "            title = f\"Polar vortex: {title}\\nP_delta: {p_delta}\",\n",
    "\n",
    "            labels = {\"speed\" : \"speed [m/s]\", \"t\" : \"t [Â°k]\"},\n",
    "        )\n",
    "\n",
    "        fig.update_traces(\n",
    "            marker=dict(symbol=\"square\",),\n",
    "            selector=dict(mode='markers')\n",
    "        )\n",
    "\n",
    "        fig['layout']['yaxis']['autorange'] = \"reversed\"\n",
    "\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_i3(df = df, df_i3 = df_i3, plot_param = \"t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(\n",
    "    data_frame = df_i3.iloc[-5000:],\n",
    "    x = \"date\",\n",
    "    y = \"p_delta\",\n",
    "\n",
    "    color_discrete_sequence = plt_style_s,\n",
    "    title = \"Index 3: Temperature\",\n",
    ")\n",
    "\n",
    "scale_show(fig)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom index 4 (local max):\n",
    " - get the local max, though all pressure levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pv_ind_4(df, metric, agg):\n",
    "    \"\"\"\n",
    "    metric = [\"speed\", \"t\"]\n",
    "    agg = [\"sum\", \"max\", \"mean\", \"median\"]\n",
    "    \"\"\"\n",
    "\n",
    "    #drop unneded cols\n",
    "    df_i4 = df[[\"date\", \"latitude\", \"t\", \"speed\"]]\n",
    "\n",
    "    #crate latitude aggregation\n",
    "    df_i4 = df_i4.groupby(by = [\"date\", \"latitude\"], as_index = False).aggregate(\n",
    "        speed_agg = (\"speed\", agg),\n",
    "        t_agg =    (\"t\", agg),\n",
    "    )\n",
    "\n",
    "    #normalize the standard deviation\n",
    "    # source: https://business.blogthinkbig.com/warning-about-normalizing-data/\n",
    "\n",
    "    #get local max for metric and agg\n",
    "    func = {\"speed\" : \"max\", \"t\" : \"min\"}\n",
    "    \n",
    "    df_i4_max = df_i4[[\"date\",f\"{metric}_agg\"]]\n",
    "    df_i4_max = df_i4_max.groupby(by = [\"date\"], as_index = False).aggregate(\n",
    "        metric_max = (f\"{metric}_agg\", func[metric]),\n",
    "    )\n",
    "\n",
    "    #append data together\n",
    "    df_i4[\"date\"] = df_i4[\"date\"].astype(str)\n",
    "    df_i4_max[\"date\"] = df_i4_max[\"date\"].astype(str)\n",
    "\n",
    "    df_i4[\"date\"] = pd.to_datetime(df_i4[\"date\"])\n",
    "    df_i4_max[\"date\"] = pd.to_datetime(df_i4_max[\"date\"])\n",
    "\n",
    "    df_i4 = df_i4.merge(right = df_i4_max, on = [\"date\"], how = \"left\")\n",
    "    \n",
    "    #only get matchin max value\n",
    "    df_i4 = df_i4.loc[df_i4[\"metric_max\"] == df_i4[f\"{metric}_agg\"]]\n",
    "    df_i4.drop(labels = \"metric_max\", axis = 1, inplace = True)\n",
    "\n",
    "    return df_i4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i4_s = pv_ind_4(df, \"speed\", \"mean\")\n",
    "df_i4_s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_i2(df, df_i4_s, \"speed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i4_t = pv_ind_4(df, \"t\", \"mean\")\n",
    "df_i4_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_i2(df, df_i4_t, \"t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i4_t[\"type\"] = \"temp\"\n",
    "df_i4_s[\"type\"] = \"speed\"\n",
    "\n",
    "df_i4 = pd.concat(objs = [df_i4_t, df_i4_s])\n",
    "df_i4.sort_values(by = \"date\", ascending = True, inplace = True)\n",
    "\n",
    "df_i4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(\n",
    "    data_frame  = df_i4.iloc[-2000:],\n",
    "    x = \"date\",\n",
    "    y = \"latitude\",\n",
    "    title = \"Polar vortex: Index 4\",\n",
    "    color_discrete_sequence = plt_style_s,\n",
    "    color = \"type\",\n",
    ")\n",
    "\n",
    "\n",
    "scale_show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temperature: index 2\n",
    "#wind speed: index 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom index 5 (SSW)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Index optimization and setting\n",
    "Sudden stratospheric warming events: https://csl.noaa.gov/groups/csl8/sswcompendium/majorevents.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 PVT: Polar vortex temp (index 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_i_breakdown(df, plot_param, break_down_date):\n",
    "\n",
    "    if plot_param == \"t\":\n",
    "        title = \"temperature\"\n",
    "    elif plot_param == \"speed\":\n",
    "        title = \"wind speed\"\n",
    "\n",
    "    plot_scaler = 19\n",
    "\n",
    "    fig = px.scatter(\n",
    "        data_frame = df,\n",
    "        x = \"latitude\",\n",
    "        y = \"level\",\n",
    "        color = plot_param,\n",
    "        size = \"size\",\n",
    "        size_max = 1 * plot_scaler - 1,\n",
    "        opacity = 1,\n",
    "        facet_row = \"date\",\n",
    "\n",
    "        height = 15 * plot_scaler * len(df[\"date\"].unique().tolist()),\n",
    "        width = 60 * plot_scaler,\n",
    "        color_continuous_scale  = plt_style_s,\n",
    "\n",
    "        title = f\"Polar vortex breakdown - {break_down_date}: {title}\",\n",
    "\n",
    "        labels = {\"speed\" : \"speed [m/s]\", \"t\" : \"t [k]\"},\n",
    "    )\n",
    "\n",
    "    fig.update_traces(\n",
    "        marker=dict(symbol=\"square\",),\n",
    "        selector=dict(mode='markers')\n",
    "    )\n",
    "\n",
    "    fig['layout']['yaxis']['autorange'] = \"reversed\"\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_i2_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimize temperatrue (i2)\n",
    "#params\n",
    "n_lat                   = 3 #lat offset for calultion\n",
    "threshold               = 1.0 #in % for vortex, multiple which has to be exceeded from popluation mean, to be counted as a pv edge\n",
    "break_down_offset       = 15 #last n span, used to detect a break down\n",
    "break_down_sensitivity  = 0.1 # in %. Sets the barrier or threshold, at which the value crossing it, a breakdown will be detected\n",
    "\n",
    "df_i2_t = PV_ind_2_v2.main(\n",
    "    df = df,\n",
    "    n_lat = n_lat,\n",
    "    threshold = threshold,\n",
    "    break_down_offset = break_down_offset,\n",
    "    break_down_sensitivity = break_down_sensitivity,\n",
    "    metric = \"t\",\n",
    ")\n",
    "\n",
    "df_i2_t.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = -1000\n",
    "\n",
    "fig = px.line(\n",
    "    data_frame = df_i2_t,\n",
    "    x = \"date\",\n",
    "    y = \"pv_break_down_event\",\n",
    "    title = \"PV break down events i2: Temperature\",\n",
    "    color_discrete_sequence = plt_style_s,\n",
    ")\n",
    "\n",
    "scale_show(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add momth\n",
    "df_i2_t[\"month\"] = pd.DatetimeIndex(df_i2_t[\"date\"]).month\n",
    "\n",
    "\n",
    "#plot porbaibilty per month\n",
    "fig = px.histogram(\n",
    "    data_frame = df_i2_t,\n",
    "    x = \"month\",\n",
    "    y = \"pv_break_down_event\",\n",
    "    histfunc = \"sum\",\n",
    "    barmode = \"stack\",\n",
    "    title = \"PV break down events i2 per month: Temperature\",\n",
    "    color_discrete_sequence = plt_style_s,\n",
    "\n",
    "    width = 700,\n",
    "    height = 700,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add momth\n",
    "df_i2_t[\"month\"] = pd.DatetimeIndex(df_i2_t[\"date\"]).month\n",
    "\n",
    "\n",
    "#plot porbaibilty per month\n",
    "fig = px.histogram(\n",
    "    data_frame = df_i2_t,\n",
    "    x = \"month\",\n",
    "    y = \"pv_edge\",\n",
    "    histfunc = \"sum\",\n",
    "    barmode = \"stack\",\n",
    "    title = \"PV edges i2: Temperature\",\n",
    "    color_discrete_sequence = plt_style_s,\n",
    ")\n",
    "\n",
    "scale_show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot breakdonw events\n",
    "df_i2_t.reset_index(inplace = True, drop = True)\n",
    "\n",
    "plot_range = 5\n",
    "\n",
    "df_i2_t[\"date\"] = df_i2_t[\"date\"].astype(str) #whyyy?\n",
    "\n",
    "for i in df_i2_t.loc[df_i2_t[\"pv_break_down_event\"] == 1].index[-4:]:\n",
    "    for param in [\"t\", \"speed\"]:\n",
    "\n",
    "        print(i)\n",
    "        break_down_date = df_i2_t.iloc[i][\"date\"]\n",
    "\n",
    "        offset = int(plot_range / 2)\n",
    "        start_date      = df_i2_t.iloc[i - offset][\"date\"]\n",
    "        end_date        = df_i2_t.iloc[i + offset][\"date\"]\n",
    "\n",
    "\n",
    "        df_plot = df.loc[(df[\"date\"] >= start_date) & (df[\"date\"] <= end_date)]\n",
    "        plot_i_breakdown(df = df_plot, plot_param = param, break_down_date = break_down_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data frame for merging\n",
    "unneded_cols = [\"speed_mean\", \"delta\", \"mean_delta\", \"month\"]\n",
    "\n",
    "for col in unneded_cols:\n",
    "\n",
    "    try:\n",
    "        df_i2_t.drop(labels = col, axis = 1, inplace = True)\n",
    "    except:\n",
    "        print(f\"{col} does not exist\")\n",
    "\n",
    "#add prefix to generate unique values\n",
    "df_i2_t = df_i2_t.add_prefix(\"pvt_\") #polar vortex temperature\n",
    "\n",
    "df_i2_t.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 PVS: Polar vortex wind speed (index 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PV_ind_4():\n",
    "\n",
    "    def main(df, metric, threshold, break_down_offset, break_down_sensitivity):\n",
    "\n",
    "        df_i4 = PV_ind_4.get_local_max(df, metric)\n",
    "        df_i4 = PV_ind_4.apply_threshold(df_i4, df, threshold, metric)\n",
    "        df_i4 = PV_ind_4.detect_breakdown(df_i4, break_down_offset, break_down_sensitivity)\n",
    "        \n",
    "        return df_i4\n",
    "\n",
    "    def get_local_max(df, metric):\n",
    "\n",
    "        #drop unneded cols\n",
    "        df_i4 = df[[\"date\", \"latitude\", \"t\", \"speed\"]]\n",
    "\n",
    "        #crate latitude aggregation\n",
    "        df_i4 = df_i4.groupby(by = [\"date\", \"latitude\"], as_index = False).aggregate(\n",
    "            speed_mean = (\"speed\", \"mean\"),\n",
    "            t_mean =    (\"t\", \"mean\"),\n",
    "        )\n",
    "\n",
    "        #get local max for metric and agg\n",
    "        func = {\"speed\" : \"max\", \"t\" : \"min\"}\n",
    "        \n",
    "        df_i4_max = df_i4[[\"date\",f\"{metric}_mean\"]]\n",
    "        df_i4_max = df_i4_max.groupby(by = [\"date\"], as_index = False).aggregate(\n",
    "            metric_max = (f\"{metric}_mean\", func[metric]),\n",
    "        )\n",
    "\n",
    "        #append data together\n",
    "        df_i4[\"date\"] = df_i4[\"date\"].astype(str)\n",
    "        df_i4_max[\"date\"] = df_i4_max[\"date\"].astype(str)\n",
    "\n",
    "        df_i4[\"date\"] = pd.to_datetime(df_i4[\"date\"])\n",
    "        df_i4_max[\"date\"] = pd.to_datetime(df_i4_max[\"date\"])\n",
    "\n",
    "        df_i4 = df_i4.merge(right = df_i4_max, on = [\"date\"], how = \"left\")\n",
    "        \n",
    "        #only get matching max value\n",
    "        df_i4 = df_i4.loc[df_i4[\"metric_max\"] == df_i4[f\"{metric}_mean\"]]\n",
    "        df_i4.drop(labels = \"metric_max\", axis = 1, inplace = True)\n",
    "\n",
    "        #drop unneded metric\n",
    "        unneded_metric = [\"t\", \"speed\"]\n",
    "        unneded_metric.remove(metric)\n",
    "        df_i4.drop(labels = f\"{unneded_metric[0]}_mean\", axis = 1, inplace = True)\n",
    "\n",
    "        return df_i4\n",
    "\n",
    "    def apply_threshold(df_i4, df, threshold, metric):\n",
    "\n",
    "        #only get needed cols\n",
    "        df_i4_mean = df[[\"date\", metric]]\n",
    "\n",
    "        #set th as multiplicator\n",
    "        th = threshold + 1\n",
    "\n",
    "        #get overall mean metric\n",
    "        df_i4_mean = df_i4_mean.groupby(by = \"date\", as_index = False).mean()\n",
    "\n",
    "        #stupid date time formats keep changing\n",
    "        df_i4_mean['date'] = df_i4_mean['date'].astype('datetime64[ns]')\n",
    "\n",
    "        #merge and apply th\n",
    "        df_i4 = df_i4.merge(right = df_i4_mean, on = \"date\", how = \"left\")\n",
    "        df_i4[metric] = df_i4[metric] * th\n",
    "\n",
    "        #check if th is exceeded\n",
    "        df_i4[\"pv_edge\"] = 0\n",
    "        df_i4.loc[df_i4[f\"{metric}_mean\"] > df_i4[metric], \"pv_edge\"] = 1\n",
    "\n",
    "        #drop unnded cols\n",
    "        df_i4.drop(labels = [metric], inplace = True, axis = 1)\n",
    "\n",
    "        return df_i4\n",
    "\n",
    "    def detect_breakdown(df_i4, break_down_offset, break_down_sensitivity):\n",
    "\n",
    "        #relevant months\n",
    "        considered_months = [12,1,2,3,4]\n",
    "\n",
    "        #consider offset by applying rolling mean.\n",
    "        df_i4[\"pv_edge_offset\"] = df_i4[\"pv_edge\"].rolling(break_down_offset).mean()\n",
    "\n",
    "        #break down event\n",
    "        df_i4[\"pv_break_down_event\"] = 0\n",
    "        df_i4.loc[\n",
    "            (df_i4[\"pv_edge_offset\"] <= break_down_sensitivity) &\n",
    "            (df_i4[\"pv_edge_offset\"].shift(1) > break_down_sensitivity) &\n",
    "            (df_i4[\"date\"].dt.month.isin(considered_months))\n",
    "            , \"pv_break_down_event\"] = 1\n",
    "\n",
    "        #clean up\n",
    "        df_i4.drop(labels = \"pv_edge_offset\", axis = 1, inplace = True)\n",
    "\n",
    "        return df_i4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold               = 0.5\n",
    "break_down_offset       = 60 #last n span, used to detect a break down\n",
    "break_down_sensitivity  = 0.875 # in %. Sets the barrier or threshold, at which the value crossing it, a breakdown will be detected\n",
    "\n",
    "df_i4_s = PV_ind_4.main(\n",
    "    df = df,\n",
    "    metric = \"speed\",\n",
    "\n",
    "    threshold = threshold,\n",
    "    break_down_offset = break_down_offset,\n",
    "    break_down_sensitivity = break_down_sensitivity,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i4_s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = -1000\n",
    "\n",
    "fig = px.line(\n",
    "    data_frame = df_i4_s,\n",
    "    x = \"date\",\n",
    "    y = \"pv_break_down_event\",\n",
    "    title = \"PV break down events i4: Wind speed\",\n",
    "    color_discrete_sequence = plt_style_s,\n",
    ")\n",
    "\n",
    "scale_show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add momth\n",
    "df_i4_s[\"month\"] = pd.DatetimeIndex(df_i4_s[\"date\"]).month\n",
    "\n",
    "\n",
    "#plot porbaibilty per month\n",
    "fig = px.histogram(\n",
    "    data_frame = df_i4_s,\n",
    "    x = \"month\",\n",
    "    y = \"pv_break_down_event\",\n",
    "    histfunc = \"sum\",\n",
    "    barmode = \"stack\",\n",
    "    title = \"PV break down events i4 per month: Wind speed\",\n",
    "    color_discrete_sequence = plt_style_s,\n",
    "\n",
    "    height = 700,\n",
    "    width = 700,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add momth\n",
    "df_i4_s[\"month\"] = pd.DatetimeIndex(df_i4_s[\"date\"]).month\n",
    "\n",
    "\n",
    "#plot porbaibilty per month\n",
    "fig = px.histogram(\n",
    "    data_frame = df_i4_s,\n",
    "    x = \"month\",\n",
    "    y = \"pv_edge\",\n",
    "    histfunc = \"sum\",\n",
    "    barmode = \"stack\",\n",
    "    title = \"PV edges i4: Temperature\",\n",
    "    color_discrete_sequence = plt_style_s,\n",
    ")\n",
    "\n",
    "scale_show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i4_s.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot breakdonw events\n",
    "df_i4_s.reset_index(inplace = True, drop = True)\n",
    "df_i4_s[\"date\"] = df_i4_s[\"date\"].astype(str)\n",
    "\n",
    "plot_range = 5\n",
    "\n",
    "for i in df_i4_s.loc[df_i4_s[\"pv_break_down_event\"] == 1].index[-4:]:\n",
    "    for param in [\"t\", \"speed\"]:\n",
    "\n",
    "        print(i)\n",
    "        break_down_date = \"2022-03-05\" #df_i4_s.iloc[i][\"date\"]\n",
    "\n",
    "        offset = int(plot_range / 2)\n",
    "        start_date      = \"2022-03-03\"#df_i4_s.iloc[i - offset][\"date\"]\n",
    "        end_date        = \"2022-03-07\"#df_i4_s.iloc[i + offset][\"date\"]\n",
    "\n",
    "        df_plot = df.loc[(df[\"date\"] >= start_date) & (df[\"date\"] <= end_date)]\n",
    "        plot_i_breakdown(df = df_plot, plot_param = param, break_down_date = break_down_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove unneded cols\n",
    "try:\n",
    "    df_i4_s.drop(labels = \"month\", axis = 1, inplace = True)\n",
    "except:\n",
    "    print(\"month col does not exist\")\n",
    "\n",
    "#add prefix\n",
    "df_i4_s = df_i4_s.add_prefix(\"pvs_\")\n",
    "\n",
    "#check\n",
    "df_i4_s.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Merge and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge data\n",
    "df_pv = df_i2_t.merge(right = df_i4_s, left_on = \"pvt_date\", right_on = \"pvs_date\", how = \"left\")\n",
    "\n",
    "#clean up\n",
    "df_pv.drop(labels = \"pvs_date\", axis = 1, inplace = True)\n",
    "df_pv.rename(mapper = {\"pvt_date\" : \"date\"}, axis = 1, inplace = True)\n",
    "\n",
    "df_pv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some plots and correlation matrix\n",
    "df_pv_plot = df_pv.copy()\n",
    "\n",
    "df_pv_plot[\"size\"] = 1\n",
    "\n",
    "\n",
    "fig = px.scatter(\n",
    "    data_frame = df_pv_plot,\n",
    "    x = \"pvs_latitude\",\n",
    "    y = \"pvt_latitude\",\n",
    "    title = \"Temperature and wind speed comparison: latitude\",\n",
    "    color_discrete_sequence = plt_style_s,\n",
    "    opacity = 0.05,\n",
    "    size_max = 17,\n",
    "    size = \"size\",\n",
    "\n",
    "    height = 1000,\n",
    "    width = 1000,\n",
    "\n",
    ")\n",
    "\n",
    "fig.update_traces(\n",
    "    marker=dict(symbol=\"square\",),\n",
    "    selector=dict(mode='markers')\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(\n",
    "    data_frame = df_pv_plot,\n",
    "    x = \"date\",\n",
    "    y = [\"pvs_pv_break_down_event\", \"pvt_pv_break_down_event\"],\n",
    "\n",
    "    title = \"Break down events\",\n",
    "    color_discrete_sequence = plt_style_s,\n",
    "\n",
    "    labels = {\"value\" : \"\"}\n",
    ")\n",
    "\n",
    "newnames = {\"pvs_pv_break_down_event\" : \"pvs breakdwon\", \"pvt_pv_break_down_event\" : \"pvt breakdown\"}\n",
    "fig.for_each_trace(lambda t: t.update(name = newnames[t.name],\n",
    "                                      legendgroup = newnames[t.name],\n",
    "                                      hovertemplate = t.hovertemplate.replace(t.name, newnames[t.name])\n",
    "                                     )\n",
    "                  )\n",
    "\n",
    "scale_show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(\n",
    "    data_frame = df_pv_plot.iloc[-2000:],\n",
    "    x = \"date\",\n",
    "    y = [\"pvs_pv_edge\", \"pvt_pv_edge\"],\n",
    "\n",
    "    title = \"PV edges\",\n",
    "    color_discrete_sequence = plt_style_s,\n",
    "\n",
    "    labels = {\"value\" : \"\"}\n",
    ")\n",
    "\n",
    "newnames = {\"pvs_pv_edge\" : \"pvs edge\", \"pvt_pv_edge\" : \"pvt edge\"}\n",
    "fig.for_each_trace(lambda t: t.update(name = newnames[t.name],\n",
    "                                      legendgroup = newnames[t.name],\n",
    "                                      hovertemplate = t.hovertemplate.replace(t.name, newnames[t.name])\n",
    "                                     )\n",
    "                  )\n",
    "\n",
    "scale_show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge with main dataframe\n",
    "df_fe = pd.read_csv(os.path.join(data_folder, \"df_fe.csv\"))\n",
    "df_fe.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"df_fe: {df_fe.shape}\\ndf_pv: {df_pv.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe = df_fe.merge(right = df_pv, left_on = \"date\", right_on = \"date\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save main data frame with added pv data\n",
    "if save_data is True:\n",
    "    df_fe.set_index(\"date\", drop = True, inplace = True)\n",
    "    df_fe.to_csv(os.path.join(data_folder, \"df_fe.csv\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Categorizing data for ml models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_folder, \"df_fe.csv\"))\n",
    "df[\"date\"] = pd.DataFrame(df[\"date\"])\n",
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for month in df[\"month\"].unique()[:3]:\n",
    "\n",
    "    fig = px.box(\n",
    "        data_frame = df.loc[(df[\"month\"] == month)],\n",
    "        x = \"day\",\n",
    "        y = \"t2m\",\n",
    "\n",
    "        title = f\"Temperature by month: {month}\",\n",
    "        color_discrete_sequence = plt_style_s,\n",
    "\n",
    "        width = size[\"width\"],\n",
    "        height = size[\"height\"] * 12,\n",
    "    )\n",
    "\n",
    "    scale_show(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate fortnight periods 1 and 2\n",
    "df[\"t2m_t1\"] = df[\"t2m\"].rolling(14).mean().shift(-14)\n",
    "df[\"t2m_t2\"] = df[\"t2m\"].rolling(14).mean().shift(-28)\n",
    "\n",
    "#set category\n",
    "df_median = df[[\"month\", \"day\", \"t2m_t1\", \"t2m_t2\"]].groupby(by = [\"month\", \"day\"], as_index = False).aggregate(\n",
    "    t2m_t1_mean = (\"t2m_t1\", \"mean\"),\n",
    "    t2m_t2_mean = (\"t2m_t2\", \"mean\"),\n",
    ")\n",
    "\n",
    "#merge df to main\n",
    "df = df.merge(right = df_median, on = [\"month\", \"day\"])\n",
    "df.sort_values(by = \"date\", inplace = True, ascending = True)\n",
    "\n",
    "#set, if value is above or below median\n",
    "df[\"t2m_t1_cat\"] = 0\n",
    "df[\"t2m_t2_cat\"] = 0\n",
    "\n",
    "df.loc[df[\"t2m_t1\"] >= df[\"t2m_t1_mean\"], \"t2m_t1_cat\"] = 1\n",
    "df.loc[df[\"t2m_t2\"] >= df[\"t2m_t2_mean\"], \"t2m_t2_cat\"] = 1\n",
    "\n",
    "#see df\n",
    "df.head(15).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    data_frame = df,\n",
    "    x = \"year\",\n",
    "    y  = \"t2m_t1_cat\",\n",
    "    color = \"t2m_t1_cat\",\n",
    "    color_discrete_sequence = plt_style_s,\n",
    "    title = \"Target variable distribution\",\n",
    "    histfunc = \"count\",\n",
    "    barmode= \"stack\"\n",
    ")\n",
    "\n",
    "scale_show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = df[[\"t2m_t1_cat\", \"t2m_t2_cat\"]]\n",
    "df_target[\"same_cat\"] = df_target[\"t2m_t1_cat\"] == df_target[\"t2m_t2_cat\"]\n",
    "\n",
    "fig = px.histogram(\n",
    "    data_frame = df_target,\n",
    "    x = \"same_cat\",\n",
    "    color = \"same_cat\",\n",
    "    histfunc = \"count\",\n",
    "    title = \"Same category in target vector (t1 = t2)\",\n",
    "    color_discrete_sequence = plt_style_s,\n",
    "\n",
    "    width = 500,\n",
    "    height = 500,\n",
    ")\n",
    "\n",
    "fig.add_hline(\n",
    "    y = len(df_target.index.tolist()) / 2,\n",
    "    line_width=3,\n",
    "    line_dash=\"dash\",\n",
    "    line_color=\"grey\",\n",
    "\n",
    "    annotation_text = \"q = 0.5\",\n",
    "    annotation_position=\"right\",\n",
    "    annotation_font_color = \"black\",\n",
    ")\n",
    "\n",
    "fig.update_layout(showlegend=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    data_frame = df_median,\n",
    "    x = df_median.index,\n",
    "    y = \"t2m_t1_mean\",\n",
    "\n",
    "    title = \"Target: t2m_mean\",\n",
    "    color_continuous_scale = plt_style_c,\n",
    "    labels = {\"t2m_t1_mean\" : \"t2m_mean [k]\"},\n",
    "\n",
    "    color = \"month\",\n",
    ")\n",
    "\n",
    "scale_show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_data is True:\n",
    "\n",
    "    try:\n",
    "        df.set_index(keys = \"date\", inplace = True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    df.to_csv(os.path.join(data_folder, \"df_main.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outlier analysis\n",
    "df_median.iloc[59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df[\"day\"].isin([27,28,29])) & (df[\"month\"] == 2)][[\"t2m\", \"sp\", \"cdir\"]].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the outlier is neglecgtable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 t2m and pv_breakdwon correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp = df[[\"date\", \"t2m\", \"pvs_latitude\", \"pvt_latitude\", \"pvt_pv_break_down_event\", \"pvs_pv_break_down_event\", \"t2m_t1_cat\", \"pvs_pv_edge\", \"pvt_pv_edge\"]]\n",
    "df_comp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation\n",
    "df_corr = df_comp.corr().round(1)\n",
    "\n",
    "# Mask to matrix\n",
    "mask = np.zeros_like(df_corr, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Viz\n",
    "df_corr_viz = df_corr.mask(mask).dropna(how='all').dropna('columns', how='all')\n",
    "\n",
    "fig = px.imshow(\n",
    "\n",
    "    df_corr_viz,\n",
    "    text_auto=True,\n",
    "    color_continuous_scale = plt_style_c,\n",
    "\n",
    "    title = \"Correlation matrix\",\n",
    "    width = 700,\n",
    "    height = 700,\n",
    "    )\n",
    "\n",
    "fig.show()\n",
    "\n",
    "del df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    data_frame = df_comp,\n",
    "    y = \"t2m\",\n",
    "    x = \"pvs_latitude\",\n",
    "    color = \"pvs_pv_break_down_event\",\n",
    "    range_color = [0,1],\n",
    "    opacity = 0.1,\n",
    "\n",
    "    color_continuous_scale = plt_style_s,\n",
    "    facet_col = \"pvs_pv_edge\",\n",
    "\n",
    "    title = \"t2m and pvs latitude correlation\",\n",
    "    labels = {\"t2m\" : \"t2m [k]\", \"pvs_pv_break_down_event\" : \"breakdown\"},\n",
    "    trendline = \"ols\",\n",
    "    trendline_color_override = \"red\",\n",
    "\n",
    ")\n",
    "\n",
    "fig.add_hline(\n",
    "    y = 273.15,\n",
    "    line_width=3,\n",
    "    line_dash=\"dash\",\n",
    "    line_color=\"dark blue\",\n",
    "\n",
    "    annotation_text = \"273.15\",\n",
    "    annotation_position=\"bottom left\",\n",
    "    annotation_font_color = \"black\",\n",
    ")\n",
    "\n",
    "scale_show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(\n",
    "    data_frame = df_comp,\n",
    "    y = \"t2m\",\n",
    "    x = \"pvs_latitude\",\n",
    "\n",
    "    title = \"t2m and pvs latitude correlation\",\n",
    "    labels = {\"t2m\" : \"t2m Â°k\"},\n",
    "    color_discrete_sequence = plt_style_s,\n",
    ")\n",
    "\n",
    "scale_show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    data_frame = df_comp,\n",
    "    y = \"t2m\",\n",
    "    x = \"pvt_latitude\",\n",
    "    color = \"pvt_pv_break_down_event\",\n",
    "        range_color = [0,1],\n",
    "    opacity = 0.1,\n",
    "\n",
    "    color_continuous_scale = plt_style_s,\n",
    "    facet_col = \"pvt_pv_edge\",\n",
    "\n",
    "    title = \"t2m and pvt latitude correlation\",\n",
    "    labels = {\"t2m\" : \"t2m [k]\", \"pvt_pv_break_down_event\" : \"breakdown\"},\n",
    "    trendline = \"ols\",\n",
    "    trendline_color_override = \"red\",\n",
    ")\n",
    "\n",
    "fig.add_hline(\n",
    "    y = 273.15,\n",
    "    line_width=3,\n",
    "    line_dash=\"dash\",\n",
    "    line_color=\"dark blue\",\n",
    "\n",
    "    annotation_text = \"273.15\",\n",
    "    annotation_position=\"bottom left\",\n",
    "    annotation_font_color = \"black\",\n",
    ")\n",
    "\n",
    "\n",
    "scale_show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 7000\n",
    "\n",
    "pvs_breakdown_list = df_comp.iloc[-n:].loc[df_comp[\"pvs_pv_break_down_event\"] == 1][\"date\"].to_list()\n",
    "\n",
    "fig = px.scatter(\n",
    "    data_frame = df_comp.iloc[-n:],\n",
    "    x = \"date\",\n",
    "    y = \"t2m\",\n",
    "    color = \"t2m_t1_cat\",\n",
    "    color_continuous_scale = plt_style_s,\n",
    "    title = \"PVS break down events\",\n",
    ")\n",
    "\n",
    "for date in pvs_breakdown_list:\n",
    "    fig.add_vline(\n",
    "        x = date,\n",
    "        \n",
    "    )\n",
    "\n",
    "\n",
    "scale_show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 7000\n",
    "\n",
    "pvt_breakdown_list = df_comp.iloc[-n:].loc[df_comp[\"pvt_pv_break_down_event\"] == 1][\"date\"].to_list()\n",
    "\n",
    "fig = px.scatter(\n",
    "    data_frame = df_comp.iloc[-n:],\n",
    "    x = \"date\",\n",
    "    y = \"t2m\",\n",
    "    color = \"t2m_t1_cat\",\n",
    "    color_continuous_scale = plt_style_s,\n",
    "    title = \"PVT break down events\",\n",
    ")\n",
    "\n",
    "for date in pvt_breakdown_list:\n",
    "    fig.add_vline(\n",
    "        x = date,\n",
    "    )\n",
    "\n",
    "\n",
    "scale_show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparison with ssw data\n",
    "#source: https://csl.noaa.gov/groups/csl8/sswcompendium/majorevents.html\n",
    "\n",
    "ssw_events = [\n",
    "    \"1958-01-01\",\"1958-11-01\",\"1960-01-01\",\"1963-01-01\",\"1965-03-01\",\"1965-12-01\",\"1966-02-01\",\"1968-01-01\",\"1968-11-01\",\"1969-03-01\",\"1970-01-01\",\"1971-01-01\",\"1971-03-01\",\"1973-01-01\",\"1977-01-01\",\"1979-02-01\",\"1980-02-01\",\"1981-02-01\",\"1981-03-01\",\"1981-12-01\",\"1984-02-01\",\"1985-01-01\",\"1987-01-01\",\"1987-12-01\",\"1988-03-01\",\"1989-02-01\",\"1998-12-01\",\"1999-02-01\",\"2000-03-01\",\"2001-02-01\",\"2001-12-01\",\"2002-02-01\",\"2003-01-01\",\"2004-01-01\",\"2006-01-01\",\"2007-02-01\",\"2008-02-01\",\"2009-01-01\",\"2010-02-01\",\"2010-03-01\",\"2013-01-01\",\"2018-02-01\",\"2019-01-01\",\n",
    "]\n",
    "\n",
    "\n",
    "df_comp[\"ssw\"] = 0\n",
    "df_comp.loc[df_comp[\"date\"].isin(ssw_events), \"ssw\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5000\n",
    "pvs_breakdown_list = df_comp.iloc[-n:].loc[df_comp[\"ssw\"] == 1][\"date\"].to_list()\n",
    "\n",
    "for col in [\"ssw\", \"pvt_pv_break_down_event\", \"pvs_pv_break_down_event\"]:\n",
    "\n",
    "    bd_list = df_comp.iloc[-n:].loc[df_comp[col] == 1][\"date\"].to_list()\n",
    "\n",
    "\n",
    "    fig = px.scatter(\n",
    "        data_frame = df_comp.iloc[-n:],\n",
    "        x = \"date\",\n",
    "        y = df_comp.iloc[-n:][\"t2m_t1_cat\"].rolling(60).mean(),\n",
    "        color = \"t2m_t1_cat\",\n",
    "        color_continuous_scale =  plt_style_s,\n",
    "        title = f\"Break down event: {col}\",\n",
    "\n",
    "        labels = {\"t2m\" : \"t2m [k]\"}\n",
    "    )\n",
    "\n",
    "    for date in bd_list:\n",
    "        fig.add_vline(\n",
    "            x = date,\n",
    "    )\n",
    "\n",
    "\n",
    "    scale_show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(\n",
    "    data_frame = df_comp,\n",
    "    x = \"date\",\n",
    "    y = [\"pvs_pv_break_down_event\", \"ssw\"],\n",
    "\n",
    "    title = \"Polar vortex break down event (pvs) and SSW comparison\",\n",
    "    color_discrete_sequence = plt_style_s,\n",
    ")\n",
    "\n",
    "scale_show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(\n",
    "    data_frame = df_comp,\n",
    "    x = \"date\",\n",
    "    y = [\"pvt_pv_break_down_event\",\"pvs_pv_break_down_event\" ,\"ssw\"],\n",
    "\n",
    "    title = \"Polar vortex break down event (pvt, pvs) and SSW comparison\",\n",
    "    color_discrete_sequence = plt_style_s,\n",
    "\n",
    "    labels = {\"value\" : \"event\", \"pvt_pv_break_down_event\" : \"pvt\",\"pvs_pv_break_down_event\" : \"pvs\"},\n",
    ")\n",
    "\n",
    "scale_show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp[[\"pvt_pv_break_down_event\", \"pvs_pv_break_down_event\", \"ssw\"]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del df_comp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
