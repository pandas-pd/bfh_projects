{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 PV image data clustering\n",
    "- process: https://towardsdatascience.com/a-step-by-step-guide-for-clustering-images-4b45f9906128\n",
    "- clustering methods: https://towardsdatascience.com/from-data-to-clusters-when-is-your-clustering-good-enough-5895440a978a\n",
    "- hog method for feature method: https://www.analyticsvidhya.com/blog/2019/09/feature-engineering-images-introduction-hog-feature-descriptor/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from datetime import datetime\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.io as pio\n",
    "\n",
    "#image clustering library\n",
    "try:\n",
    "    from clustimage import Clustimage\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#machine learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#folders\n",
    "data_folder = \"data\"\n",
    "\n",
    "#warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set if data should be safed\n",
    "save_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot styles\n",
    "plt_style_c = px.colors.sequential.haline #complex\n",
    "plt_style_s = px.colors.diverging.Portland #simple\n",
    "\n",
    "#defualt plot size \n",
    "size = {\n",
    "    \"width\" : 1500 ,\n",
    "    \"height\" : 750 ,\n",
    "}\n",
    "\n",
    "#function for plotting\n",
    "def scale_show(fig, size_override = False):\n",
    "\n",
    "    #set font\n",
    "    fig.update_layout(\n",
    "        font = dict(size=16),\n",
    "        title_font = dict(size=20),\n",
    "        xaxis_title_font = dict(size=18),\n",
    "        yaxis_title_font = dict(size=18),\n",
    "    )\n",
    "\n",
    "    #set size\n",
    "    if size_override == False:\n",
    "        fig.update_layout(\n",
    "            width=1500,\n",
    "            height=750,\n",
    "        )\n",
    "\n",
    "    #show\n",
    "    fig.show()\n",
    "\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_folder, \"df_pv_clustering.csv\"))\n",
    "#df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df.drop(labels = \"longitude\", axis = 1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by = [\"date\", \"level\", \"latitude\"], ascending = [True, True, True], inplace = True)\n",
    "df.reset_index(inplace = True, drop = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dates     = df[\"date\"].unique().shape[0]\n",
    "n_lats      = df[\"latitude\"].unique().shape[0]\n",
    "n_levels    = df[\"level\"].unique().shape[0]\n",
    "\n",
    "print(n_dates)\n",
    "print(n_lats)\n",
    "print(n_levels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost: high\n",
    "\n",
    "\"\"\"\n",
    "metric = \"speed\" #[\"speed\", \"t\"]\n",
    "images_na = {}\n",
    "\n",
    "for date in df[\"date\"].unique().tolist()[:3]:\n",
    "    im = []\n",
    "\n",
    "    for level in df[\"level\"].unique():\n",
    "        metrics = df.loc[(df[\"date\"] == date) & (df[\"level\"] == level)][\"speed\"].tolist()\n",
    "        im.append(metrics)\n",
    "    \n",
    "    print(f\"Compiling image: {date}\", end = \"\\r\")\n",
    "    images_na[date] = im\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_compiler(df, metric):\n",
    "\n",
    "    n_lats      = df[\"latitude\"].unique().shape[0]\n",
    "    n_levels    = df[\"level\"].unique().shape[0]\n",
    "\n",
    "    pixel_row = []\n",
    "    image = []\n",
    "    images = []\n",
    "\n",
    "    #standardize pixels\n",
    "    pixels = (df[metric] - df[metric].mean()) / df[metric].std()\n",
    "    pixels = pixels.tolist()\n",
    "\n",
    "    for pixel in pixels:\n",
    "\n",
    "        pixel_row.append(pixel)\n",
    "\n",
    "        if len(pixel_row) == n_lats:\n",
    "            image.append(np.array(pixel_row.copy()))\n",
    "            pixel_row.clear()\n",
    "\n",
    "            if len(image) == n_levels:\n",
    "                images.append(np.array(image.copy()))\n",
    "                image.clear()\n",
    "\n",
    "    images = np.stack(images)\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = image_compiler(df = df, metric = \"speed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checksum\n",
    "print(df.shape[0] / (n_lats * n_levels))\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(images[0], title = \"Wind speed standardized\", color_continuous_scale = plt_style_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(images[-1], title = \"Wind speed standardized\", color_continuous_scale = plt_style_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data, no validiotn and test sset\n",
    "\n",
    "def splitter (images):\n",
    "\n",
    "    images = images.copy() #prevent altering the original list\n",
    "\n",
    "    train_split     = 0.8\n",
    "    test_split      = 0.2  #only used for idication\n",
    "\n",
    "    index_list = list(range(len(images)))\n",
    "    train_size = int(len(images) * train_split)\n",
    "\n",
    "    train_set_i     = random.sample(population = index_list, k = train_size)\n",
    "    test_set_i      = [index for index in index_list if index not in train_set_i]\n",
    "\n",
    "    train_set       = [images[i] for i in train_set_i]\n",
    "    test_set        = [images[i] for i in test_set_i]\n",
    "\n",
    "    train_set = np.stack(train_set)\n",
    "    test_set = np.stack(test_set)\n",
    "\n",
    "    print(f\"train set:\\t{round(len(train_set) / len(images), 2)}\\ntest set:\\t{round(len(test_set) / len(images),2)}\")\n",
    "\n",
    "    #match indexes in df to indexes in sets\n",
    "    index_matcher = {\n",
    "        \"train\" : {\n",
    "            \"df_i\" :    train_set_i,\n",
    "            \"set_i\" :   list(range(len(train_set))),\n",
    "        },\n",
    "        \"test\" : {\n",
    "            \"df_i\" :    test_set_i,\n",
    "            \"set_i\":    list(range(len(test_set))),\n",
    "        },\n",
    "    }\n",
    "\n",
    "    return train_set, test_set, index_matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set, index_matcher = splitter(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[0].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 modelling (clustimage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cl = Clustimage(\n",
    "        method='hog',\n",
    "        embedding='tsne',\n",
    "        grayscale=False,\n",
    "        dim=(10,45),\n",
    "\n",
    "        params_hog = {\n",
    "            \"orientations\"      : 8,\n",
    "            \"pixels_per_cell\"   : (4,4),\n",
    "        },\n",
    "\n",
    "        verbose = True,\n",
    "    )\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    results = cl.fit_transform(\n",
    "        train_set,\n",
    "        cluster='agglomerative',\n",
    "        evaluate='silhouette',\n",
    "        metric='euclidean',\n",
    "        linkage='ward',\n",
    "        min_clust=3,\n",
    "        max_clust=15,\n",
    "        cluster_space='high',\n",
    "    )\n",
    "except :\n",
    "    print(\"Not able to conver the datatypes of numpy arrays to image data. Twat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    #create model\n",
    "    cl = Clustimage(method='hog')\n",
    "\n",
    "    #extract features\n",
    "    train_set_feat = cl.extract_feat(train_set)\n",
    "\n",
    "    # Embedding using tSNE\n",
    "    xycoord = cl.embedding(train_set_feat)\n",
    "\n",
    "    # Cluster with all default settings\n",
    "    labels = cl.cluster(\n",
    "        cluster='agglomerative',\n",
    "        evaluate='silhouette',\n",
    "        metric='euclidean',\n",
    "        linkage='ward',\n",
    "        min_clust=3,\n",
    "        max_clust=15,\n",
    "        cluster_space='high',\n",
    "    )\n",
    "\n",
    "    # Return\n",
    "    results = cl.results\n",
    "\n",
    "except:\n",
    "    print(\"Not able to conver the datatypes of numpy arrays to image data. Twat\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 modelling (skealrn)\n",
    "- https://medium.com/@chengweizhang2012/how-to-do-unsupervised-clustering-with-keras-9e1284448437"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMC():\n",
    "\n",
    "    def __init__ (self, n_cluster, train_set, test_set):\n",
    "\n",
    "        #set unflattended valus\n",
    "        self.train_set      = train_set.copy()\n",
    "        self.test_set       = test_set.copy()\n",
    "        \n",
    "        #model params\n",
    "        self.random_state   = 42\n",
    "        self.n_cluster      = n_cluster\n",
    "        self.algorithm      = \"full\"\n",
    "\n",
    "        #flatten values\n",
    "        self.train_set_flat     = self.reshape(self.train_set)\n",
    "        self.test_set_flat      = self.reshape(self.test_set)\n",
    "\n",
    "    def reshape(self, set):\n",
    "\n",
    "        n_samples, height, width = set.shape\n",
    "        images_flat = set.reshape((n_samples, height * width))\n",
    "\n",
    "        return images_flat\n",
    "\n",
    "    def create_model(self):\n",
    "\n",
    "        self.model = KMeans(\n",
    "            n_clusters      = self.n_cluster,\n",
    "            random_state    = self.random_state,\n",
    "            algorithm       = self.algorithm,\n",
    "        )\n",
    "\n",
    "        self.model.fit(self.train_set_flat)\n",
    "        self.__predict_match()\n",
    "\n",
    "        return\n",
    "\n",
    "    def __predict_match(self):\n",
    "\n",
    "        #match image and labels for analysis (train)\n",
    "        labels_train = self.model.labels_\n",
    "        self.labels = []\n",
    "\n",
    "        for i in range(len(labels_train)):\n",
    "\n",
    "            data = {\n",
    "                \"set\"   : \"train\",\n",
    "                \"label\" : labels_train[i],\n",
    "                \"im\"    : self.train_set[i],\n",
    "            }\n",
    "            self.labels.append(data)\n",
    "\n",
    "        #match image and labels for analysis (test)\n",
    "        labels_test = self.model.predict(self.test_set_flat)\n",
    "\n",
    "        for i in range(len(labels_test)):\n",
    "\n",
    "            data = {\n",
    "                \"set\"   : \"test\",\n",
    "                \"label\" : labels_test[i],\n",
    "                \"im\"    : self.test_set[i],\n",
    "            }\n",
    "            self.labels.append(data)\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmc = KMC(n_cluster = 9, train_set = train_set, test_set = test_set)\n",
    "kmc.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = pd.DataFrame(kmc.labels)\n",
    "df_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    data_frame = df_cluster,\n",
    "    x = \"label\",\n",
    "    histfunc = \"count\",\n",
    "    histnorm = \"probability density\",\n",
    "    color = \"set\",\n",
    "    barmode = \"group\",\n",
    "\n",
    "    title = \"KMeans Clusters\",\n",
    "    color_discrete_sequence = plt_style_s,\n",
    ")\n",
    "\n",
    "scale_show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmc.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a sample from each cluster to get an idea of the distribution\n",
    "label_indexes = {}\n",
    "sample_plots = 3\n",
    "\n",
    "for label in df_cluster[\"label\"].unique().tolist():\n",
    "    indexes = df_cluster.loc[df_cluster[\"label\"] == label].index.tolist()\n",
    "    label_indexes[label] = indexes\n",
    "\n",
    "\n",
    "#get first elemt of each cluster and plot image\n",
    "keys = list(label_indexes.keys())\n",
    "keys.sort()\n",
    "\n",
    "for label in keys:\n",
    "\n",
    "    for i in range(sample_plots):\n",
    "\n",
    "        im_ind_all = label_indexes[label]\n",
    "        im_ind = random.sample(population = im_ind_all, k = 1, )[0]\n",
    "\n",
    "        #retrvie data for plotting\n",
    "        im_data     = kmc.labels[im_ind][\"im\"]\n",
    "        im_label    = kmc.labels[im_ind][\"label\"]\n",
    "        im_set      = kmc.labels[im_ind][\"set\"]\n",
    "\n",
    "        #generate image plot\n",
    "        fig = px.imshow(\n",
    "            im_data,\n",
    "            title = f\"Wind speed (norm) - Label: {im_label} ({im_set})\",\n",
    "            color_continuous_scale = plt_style_s,\n",
    "            range_color = [-2,6],\n",
    "            width = 1500,\n",
    "            height = 500,\n",
    "            )\n",
    "\n",
    "        fig.update_xaxes(title_text=\"Latitude (offset by -44)\")\n",
    "        fig.update_yaxes(title_text=\"Pressure level [hPa]\")\n",
    "\n",
    "        #image_file = \"test.png\"\n",
    "        #pio.write_image(fig, image_file, engine=\"plotly.io\")\n",
    "\n",
    "        #fig.write_image(\"test.png\") #f\"Wind_speed_(norm)-Label:{im_label}({im_set}).png\"\n",
    "\n",
    "        #scale_show(fig, size_override = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mach df data with image clusets\n",
    "df_index_train = pd.DataFrame(index_matcher[\"train\"])\n",
    "df_index_test = pd.DataFrame(index_matcher[\"test\"])\n",
    "\n",
    "df_index = pd.concat(objs = [df_index_train, df_index_test])\n",
    "\n",
    "df_index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster.iloc[2][\"im\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster.reset_index(inplace = True, drop = False)\n",
    "df_cluster.rename(axis = 1, mapper = {\"index\" : \"set_i\"}, inplace = True)\n",
    "df_cluster = pd.merge(left = df_cluster, right = df_index, left_on = \"set_i\", right_on = \"set_i\")\n",
    "df_cluster.drop(labels = \"set_i\", inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date = pd.DataFrame(\n",
    "    data = {\n",
    "        \"date\"      : df[\"date\"].unique().tolist(),\n",
    "    }\n",
    ")\n",
    "\n",
    "df_date.reset_index(inplace = True, drop = False)\n",
    "df_date.rename(axis = 1, mapper = {\"index\" : \"df_i\"}, inplace = True)\n",
    "\n",
    "df_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = pd.merge(left = df_cluster, right = df_date, left_on = \"df_i\", right_on = \"df_i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster[\"month\"] = df_cluster[\"date\"].astype(str).apply(lambda value: int(value[5:7]))\n",
    "df_cluster[\"year\"] = df_cluster[\"date\"].astype(str).apply(lambda value: int(value[0:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    data_frame = df_cluster.sort_values(\"label\", ascending = True, axis = 0),\n",
    "    x = \"month\",\n",
    "    y = \"label\",\n",
    "    histfunc = \"count\",\n",
    "    histnorm = \"density\",\n",
    "    title = \"Distribution of clusters\",\n",
    "    color_discrete_sequence = plt_style_c,\n",
    "    facet_row = \"label\",\n",
    "    width = 1250,\n",
    "    height = 3000,\n",
    ")\n",
    "\n",
    "scale_show(fig, size_override = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    data_frame = df_cluster.sort_values(\"month\", ascending = True, axis = 0),\n",
    "    x = \"label\",\n",
    "    histfunc = \"count\",\n",
    "    histnorm = \"density\",\n",
    "    title = \"Distribution of clusters\",\n",
    "    color_discrete_sequence = plt_style_c,\n",
    "    facet_row = \"month\",\n",
    "    width = 750,\n",
    "    height = 3000,\n",
    ")\n",
    "\n",
    "scale_show(fig, size_override = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    data_frame = df_cluster.sort_values(\"year\", ascending = True, axis = 0),\n",
    "    x = \"year\",\n",
    "    y = \"label\",\n",
    "    histfunc = \"count\",\n",
    "    histnorm = \"density\",\n",
    "    title = \"Distribution of clusters\",\n",
    "    color_discrete_sequence = plt_style_c,\n",
    "    facet_row = \"label\",\n",
    "    width = 750,\n",
    "    height = 3000,\n",
    ")\n",
    "\n",
    "scale_show(fig, size_override = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
