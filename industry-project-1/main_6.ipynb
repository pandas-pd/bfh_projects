{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "#machine learning preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# machine learning sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from pandas.api.types import is_object_dtype, is_numeric_dtype\n",
    "\n",
    "#machine learning pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y, yhat):\n",
    "    return np.sqrt(mean_squared_error(y, yhat))\n",
    "\n",
    "def dtype_as_category(df):\n",
    "\n",
    "    for column in df.keys():\n",
    "        if is_object_dtype(df[column]):\n",
    "            df[column] = df[column].astype('category')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Correct Biases (graph neural network)\n",
    "Note: For this section, only the raw data is relevant in order to minimize calulation times for the neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Define node and node features (e.g. Turbines)\n",
    "Lorem Ipsum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Define edge and edge features (e.g. Positional relationship)\n",
    "Lorem Ipsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_dir : str         = \"g_drive_data\"\n",
    "ip_dir : str        = \"ip_forecast_data\"\n",
    "main_dir :str       = \"main_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(main_dir, \"df_main_interpolated_fe.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_mapping : dict = {\n",
    "    \"front\" : 0,\n",
    "    \"back\" : 1,\n",
    "}\n",
    "df[\"position\"] = df[\"position\"].map(pos_mapping)\n",
    "df = dtype_as_category(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the relevant columns for dataframes\n",
    "\n",
    "relevant_all : list     = [\"wt_id\", \"power_kw\", \"day_sin\", \"day_cos\", \"year_sin\", \"year_cos\", \"position\", \"month\"]\n",
    "\n",
    "relevant_3 : list       = [x for x in df.columns.tolist() if (\"3\" in x and \"deviation\" not in x)]\n",
    "relevant_6 : list       = [x for x in df.columns.tolist() if (\"6\" in x and \"deviation\" not in x)]\n",
    "relevant_12 : list      = [x for x in df.columns.tolist() if (\"12\" in x and \"deviation\" not in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the dfs for the relevant time frames\n",
    "df_3        = df[relevant_all + relevant_3]\n",
    "df_6        = df[relevant_all + relevant_6]\n",
    "df_12       = df[relevant_all + relevant_12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_3_raw:\t(28305, 14)\n",
      "df_6_raw:\t(28210, 14)\n",
      "df_12_raw:\t(28210, 14)\n"
     ]
    }
   ],
   "source": [
    "#creat dfs with raw forecast data\n",
    "\n",
    "def get_raw_df(df : object, g_dir : str = g_dir, t : str = None) -> object:\n",
    "    \n",
    "    relevant_timestamps = pd.read_csv(os.path.join(g_dir, \"forecasts_temp.csv\"))\n",
    "    data_points = pd.to_datetime(relevant_timestamps[\"init\"]).dt.tz_localize(None)\n",
    "    df_raw = df[pd.to_datetime(df[f\"init_{t}\"]).dt.tz_localize(None).isin(data_points)]\n",
    "\n",
    "    print(f\"df_{t}_raw:\\t{df_raw.shape}\")\n",
    "    return df_raw\n",
    "\n",
    "df_3_raw    = get_raw_df(df_3, g_dir = g_dir, t = 3)\n",
    "df_6_raw    = get_raw_df(df_6, g_dir = g_dir, t = 6)\n",
    "df_12_raw   = get_raw_df(df_12, g_dir = g_dir, t = 12)\n",
    "\n",
    "for df_n in [df_3, df_3_raw, df_6, df_6_raw, df_12, df_12_raw]:\n",
    "    cols = [x for x in df_n.columns.tolist() if \"init\" in x]\n",
    "    df_n.drop(labels = cols, axis = 1,inplace = True)\n",
    "\n",
    "del df_3, df_6, df_12 #freeing up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wt_id', 'power_kw', 'day_sin', 'day_cos', 'year_sin', 'year_cos', 'position', 'month', 'temp_3.00', 'wind_speed_3.00', 'wind_direction_3.00', 'density_3.00', 'power_3.00']\n"
     ]
    }
   ],
   "source": [
    "print(df_3_raw.columns.tolist())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6bbfc4e4f578cb9f7c85fe350d2fab0be0faacc19ccc874c1f1be2572a1188f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
