{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "#machine learning preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from pandas.api.types import is_object_dtype, is_numeric_dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y, yhat):\n",
    "    return np.sqrt(mean_squared_error(y, yhat))\n",
    "\n",
    "def dtype_as_category(df):\n",
    "\n",
    "    for column in df.keys():\n",
    "        if is_object_dtype(df[column]):\n",
    "            df[column] = df[column].astype('category')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Correct biases and predictions (noraml models)\n",
    "### 5.1 Create the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_dir : str         = \"g_drive_data\"\n",
    "ip_dir : str        = \"ip_forecast_data\"\n",
    "main_dir :str       = \"main_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(main_dir, \"df_main_interpolated_fe.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_mapping : dict = {\n",
    "    \"front\" : 0,\n",
    "    \"back\" : 1,\n",
    "}\n",
    "df[\"position\"] = df[\"position\"].map(pos_mapping)\n",
    "df = dtype_as_category(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the relevant columns for dataframes\n",
    "\n",
    "relevant_all : list     = [\"wt_id\", \"power_kw\", \"day_sin\", \"day_cos\", \"year_sin\", \"year_cos\", \"position\", \"month\"]\n",
    "\n",
    "relevant_3 : list       = [x for x in df.columns.tolist() if (\"3\" in x and \"deviation\" not in x)]\n",
    "relevant_6 : list       = [x for x in df.columns.tolist() if (\"6\" in x and \"deviation\" not in x)]\n",
    "relevant_12 : list      = [x for x in df.columns.tolist() if (\"12\" in x and \"deviation\" not in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3        = df[relevant_all + relevant_3]\n",
    "df_6        = df[relevant_all + relevant_6]\n",
    "df_12       = df[relevant_all + relevant_12]\n",
    "\n",
    "df_3.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a validation set for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creat dfs with raw forecast data\n",
    "\n",
    "def get_raw_df(df : object, g_dir : str = g_dir, t : str = None) -> object:\n",
    "    \n",
    "    relevant_timestamps = pd.read_csv(os.path.join(g_dir, \"forecasts_temp.csv\"))\n",
    "    data_points = pd.to_datetime(relevant_timestamps[\"init\"]).dt.tz_localize(None)\n",
    "    df_raw = df[pd.to_datetime(df[f\"init_{t}\"]).dt.tz_localize(None).isin(data_points)]\n",
    "\n",
    "    print(f\"df_{t}_raw:\\t{df_raw.shape}\")\n",
    "    return df_raw\n",
    "\n",
    "df_3_raw    = get_raw_df(df_3, g_dir = g_dir, t = 3)\n",
    "df_6_raw    = get_raw_df(df_6, g_dir = g_dir, t = 6)\n",
    "df_12_raw   = get_raw_df(df_12, g_dir = g_dir, t = 12)\n",
    "\n",
    "for df_n in [df_3, df_3_raw, df_6, df_6_raw, df_12, df_12_raw]:\n",
    "    cols = [x for x in df_n.columns.tolist() if \"init\" in x]\n",
    "    df_n.drop(labels = cols, axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Define a ML model\n",
    "For a first try the random forest regressor is used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Train a ML model with\n",
    "\n",
    "Question: Should the error for the machine learning model be meassured and optimsed for mean deviation or mse or rmse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the benchmark metrics for the judgment of the prediction\n",
    "\n",
    "bench_mark : dict = {\n",
    "    \"fc_range\" : [],\n",
    "    \"type\" : [],\n",
    "    \"mse\" : [],\n",
    "    \"rmse\" : [],\n",
    "}\n",
    "\n",
    "for df, type, fc in zip([df_3, df_6, df_12, df_3_raw ,df_6_raw, df_12_raw], [\"ip\", \"ip\", \"ip\", \"raw\", \"raw\", \"raw\"], [\"3\",\"6\",\"12\",\"3\",\"6\",\"12\"]):\n",
    "\n",
    "        mse_bench : float       = mean_squared_error(df[f\"power_{fc}.00\"], df[\"power_kw\"])\n",
    "        rmse_bench : float      = np.sqrt(mse_bench)\n",
    "\n",
    "        bench_mark[\"fc_range\"].append(fc)\n",
    "        bench_mark[\"type\"].append(type)\n",
    "        bench_mark[\"mse\"].append(mse_bench)\n",
    "        bench_mark[\"rmse\"].append(rmse_bench)\n",
    "\n",
    "df_bench = pd.DataFrame(bench_mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#framework for autmated training (6 models)\n",
    "\n",
    "class RFR(): #Random Forest Regressor\n",
    "\n",
    "    log_file : str = \"random_forest_results.csv\"\n",
    "\n",
    "    def __init__ (self, df, random_state : int = 42, test_size : float = 0.3, y_col : str = \"power_kw\", offset : int = None, raw : bool = None, n_jobs = 1) -> None:\n",
    "\n",
    "        self.df                     = df\n",
    "        self.y_col : str            = y_col\n",
    "\n",
    "        self.random_state : int     = random_state\n",
    "        self.test_size : float      = test_size\n",
    "        self.n_jobs : int           = n_jobs\n",
    "\n",
    "        self.offset = offset\n",
    "        self.raw = raw\n",
    "\n",
    "        self._split()\n",
    "\n",
    "        return\n",
    "\n",
    "    def _split(self) -> None:\n",
    "        \"\"\"autmatically splits the dataframe into a train and test\"\"\"\n",
    "\n",
    "        y = self.df[self.y_col]\n",
    "        x = self.df.drop(labels = self.y_col, axis = 1)\n",
    "\n",
    "        self.X_train, self.X_valid, self.y_train, self.y_valid = train_test_split(\n",
    "            x,\n",
    "            y,\n",
    "            test_size = self.test_size,\n",
    "            random_state = self.random_state\n",
    "        )\n",
    "\n",
    "        return\n",
    "\n",
    "    def _log_results(self, estimator : int, leaf : int, mse : int, rmse : int) -> None:\n",
    "        \"\"\"logs the results and model parameter\"\"\"\n",
    "\n",
    "        #check if file exists and create it if it is missing\n",
    "        try:\n",
    "            f = pd.read_csv(RFR.log_file)\n",
    "            del f\n",
    "\n",
    "        except FileNotFoundError:\n",
    "\n",
    "            header : list = \"offset,raw,n_estimators,n_leafs,random_state,mse,rmse\".split(\",\")\n",
    "\n",
    "            f = open(RFR.log_file, \"a\", newline = \"\")\n",
    "            writer_obj = csv.writer(f)\n",
    "            writer_obj.writerow(header)\n",
    "            f.close()\n",
    "\n",
    "        #log message\n",
    "        row = [self.offset, self.raw,estimator,leaf,self.random_state,mse,rmse]\n",
    "\n",
    "        f = open(RFR.log_file, \"a\", newline = \"\")\n",
    "        writer_obj = csv.writer(f)\n",
    "        writer_obj.writerow(row)\n",
    "        f.close()\n",
    "\n",
    "        return\n",
    "\n",
    "    @staticmethod\n",
    "    def _generate_lists(opt_estimator : bool, n_fib : int, n_estimators : int, n_leafs : int) -> list:\n",
    "        \"\"\"Generates the list for the leaves and estimators to iterate through\"\"\"\n",
    "\n",
    "        fib_list : list = [1,2]\n",
    "        list(map(lambda x : fib_list.append(fib_list[-1] + fib_list[-2]),range(n_fib)))\n",
    "\n",
    "        if opt_estimator == True:\n",
    "            estimators : list       = fib_list\n",
    "            leafs : list           = [n_leafs]\n",
    "\n",
    "        elif opt_estimator == False:\n",
    "            estimators : list       = [n_estimators]\n",
    "            leafs : list           = fib_list\n",
    "\n",
    "        elif (n_estimators != 1) and (n_leafs != 1):\n",
    "            estimators = [n_estimators]\n",
    "            leafs = [n_leafs]\n",
    "\n",
    "        return estimators, leafs\n",
    "\n",
    "    def train(self, opt_estimator : bool = True, n_fib : int = None, n_estimators : int = 1, n_leafs : int = 1):\n",
    "        \"\"\"trains the model with a list of parameters\"\"\"\n",
    "\n",
    "        estimators, leafs = RFR._generate_lists(\n",
    "                opt_estimator = opt_estimator,\n",
    "                n_fib = n_fib,\n",
    "                n_estimators = n_estimators,\n",
    "                n_leafs = n_leafs,\n",
    "        )\n",
    "\n",
    "        total_itterations : int     = max(len(estimators),len(leafs)) - 2\n",
    "        current_itteration : int    = 0\n",
    "\n",
    "        for estimator in estimators:\n",
    "            for leaf in leafs:\n",
    "\n",
    "                #print to see progress\n",
    "                current_itteration += 1\n",
    "                progress : float = round(current_itteration/total_itterations,4)\n",
    "                print(f\"progress:\\t{progress}\", end = \"\\r\")\n",
    "\n",
    "                #instantciate model\n",
    "                model = RandomForestRegressor(\n",
    "                    n_estimators    = estimator,\n",
    "                    bootstrap       = False, #not nescecarry, beauce there is enough data\n",
    "                    oob_score       = False,\n",
    "                    random_state    = self.random_state,\n",
    "                    n_jobs = self.n_jobs,\n",
    "                    min_samples_leaf= leaf,\n",
    "                )\n",
    "\n",
    "                #fit model and make predictions\n",
    "                model.fit(self.X_train, self.y_train)\n",
    "                y_hat_valid = model.predict(self.X_valid)\n",
    "\n",
    "\n",
    "                mse = mean_squared_error(self.y_valid, y_hat_valid)\n",
    "                rmse = np.sqrt(mse)\n",
    "\n",
    "                self._log_results(estimator = estimator, leaf = leaf, mse = mse, rmse = rmse)\n",
    "\n",
    "    def cross_validate(self):\n",
    "        pass\n",
    "\n",
    "    def fitting_graph(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preformance test\n",
    "import time\n",
    "\n",
    "def performance_comp():\n",
    "\n",
    "    #single core performance\n",
    "    start = time.time()\n",
    "\n",
    "    model_3 = RFR(df = df_3_raw, offset = 3, raw = True, n_jobs = 1)\n",
    "    model_3.train(opt_estimator = True, n_fib = 10)\n",
    "    df_3_raw.head()\n",
    "\n",
    "    print(f\"runtime:\\t{int(time.time() - start)}\\t sec\")\n",
    "\n",
    "    #multi core performance\n",
    "    start = time.time()\n",
    "\n",
    "    model_3 = RFR(df = df_3_raw, offset = 3, raw = True, n_jobs = -1)\n",
    "    model_3.train(opt_estimator = True, n_fib = 10)\n",
    "    df_3_raw.head()\n",
    "\n",
    "    print(f\"runtime:\\t{int(time.time() - start)}\\t sec\")\n",
    "\n",
    "#performance_comp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the class\n",
    "\n",
    "#model_3 = RFR(df = df_3_raw, offset = 3, raw = True)\n",
    "#model_3.train(fibonacci = True, n_fib = 10)\n",
    "#df_3_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create validaiton dfs for later use\n",
    "valid_size : float      = 0.1 #percentag of size\n",
    "random_state : int      = 42 \n",
    "df_valid_dict : dict         = {} #continer for validation objects\n",
    "\n",
    "for df, name in zip([df_3,df_3_raw,df_6,df_6_raw,df_12,df_12_raw],\n",
    "                    \"df_3,df_3_raw,df_6,df_6_raw,df_12,df_12_raw\".split(\",\")):\n",
    "\n",
    "    print (f\"{name}\\nInitial df size:\\t{df.shape}\")\n",
    "\n",
    "    df_subset : object = df.sample(frac = 0.1, replace = False, random_state = random_state)\n",
    "    df.drop(index = df_subset.index, inplace = True)\n",
    "\n",
    "    df_valid_dict[name] = df_subset\n",
    "    print(f\"cropped df size:\\t{df.shape}\\nvalidation df size:\\t{df_subset.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runtime ca. 5 hours (?)\n",
    "#calcuates the optimal number of leves and estimators for the three offsets, once with and once without interpolated data points\n",
    "#def train(self, opt_estimator : bool = True, n_fib : int = None, n_estimators : int = 1, n_leafs : int = 1)\n",
    "\n",
    "run_automation : bool = False\n",
    "\n",
    "if run_automation:\n",
    "\n",
    "    print(\"Training with ip data\")\n",
    "\n",
    "    for df, offset in zip([df_3,df_6,df_12],[3,6,12]):\n",
    "\n",
    "        print(f\"{offset} in porgress\")\n",
    "        model = RFR(df = df, offset = offset, raw = False)\n",
    "        model.train(opt_estimator = True, n_fib = 10)\n",
    "\n",
    "    print(\"training with ip data\")\n",
    "\n",
    "    for df, offset in zip([df_3_raw,df_6_raw,df_12_raw],[3,6,12]):\n",
    "\n",
    "        print(f\"{offset} in porgress\")\n",
    "        model = RFR(df = df, offset = offset, raw = True)\n",
    "        model.train(opt_estimator = True, n_fib = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results : object     = pd.read_csv(RFR.log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting graph\n",
    "fig = px.line(\n",
    "    data_frame = df_results,\n",
    "    y = \"rmse\",\n",
    "    x = \"n_estimators\",\n",
    "    color = \"offset\",\n",
    "    facet_col = \"raw\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following n_estimators will be chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators : dict = {\n",
    "    \"df_3_raw\"      : 55,\n",
    "    \"df_6_raw\"      : 55,\n",
    "    \"df_12_raw\"     : 34,\n",
    "    \"df_3\"          : 34,\n",
    "    \"df_6\"          : 34,\n",
    "    \"df_12\"         : 34,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimze for leafs\n",
    "\n",
    "run_automation : bool = True\n",
    "\n",
    "if run_automation:\n",
    "\n",
    "    print(\"Training with ip data\")\n",
    "\n",
    "    for df, offset, n_estimators in zip([df_3,df_6,df_12],[3,6,12],[34,34,34]):\n",
    "\n",
    "        print(f\"{offset} in porgress\")\n",
    "        model = RFR(df = df, offset = offset, raw = False)\n",
    "        model.train(opt_estimator = False, n_fib = 10, n_estimators = n_estimators)\n",
    "\n",
    "    print(\"training with ip data\")\n",
    "\n",
    "    for df, offset, n_estimators in zip([df_3_raw,df_6_raw,df_12_raw],[3,6,12],[55,55,34]):\n",
    "\n",
    "        print(f\"{offset} in porgress\")\n",
    "        model = RFR(df = df, offset = offset, raw = True)\n",
    "        model.train(opt_estimator = False, n_fib = 10, n_estimators = n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "90b409ed84bde92b71afc0f8ea19cd262323d45cacbb1f5c471840b2909a3415"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
